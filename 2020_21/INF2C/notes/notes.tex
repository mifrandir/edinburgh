\documentclass{article}
\usepackage{notes-preamble}
\mkthms

\newcommand{\T}[1]{\texttt{#1}}
\begin{document}
\title{Introduction to Computer Systems (SEM3)}
\author{Franz Miltz}
\maketitle
\tableofcontents
\pagebreak
\section{Data Representation}
Data representation affects
\begin{itemize}
	\item complexity of circuits
	\item cost
	\item speed 
	\item reliability
\end{itemize}
\subsection{The bit}
Advantages:
\begin{itemize}
	\item easy to use
	\item very reliable
	\item simple \& reusable circuits
\end{itemize}
Downside: Low information density
\subsection{Fixed bit-length arithmetic}
Issue: Hardware cannot operate on infinitely big numbers.
\begin{definition}
	An \textbf{Overflow} happens when a result does not fit the representation.
	Arithmetic therefore is module $2^N$, where $N$ is the number of bits.
\end{definition}
\subsection{Negative numbers}
\subsubsection{Sign-magnitude representation}
\begin{itemize}
	\item use MSB as the sign
	\item $1$ means negative, $0$ means positive
\end{itemize}
Problems: \begin{itemize}
	\item Complicates addition and substraction
	\item has positive and negative zero
\end{itemize}
\subsubsection{Two's complement representation}
Idea:
\begin{itemize}
	\item Want: $X + (-X) = 0$
	\item With fixed length arithmetic: $X + (-X) \equiv 0 \mod 2^N$
	\item Approach:
	\begin{itemize}
		\item Represent $-X$ as $2^N-X$
		\item Then $X + (-X) = X + (2^N - X) = 2^N$ and $2^N \equiv 0 \mod 2^N$
	\end{itemize}
\end{itemize}
Properties:
\begin{itemize}
	\item The MSB is the sign
	\item Change $X$ to $-X$ is easy: Flip the bits and add $1$
	\item $A-B$ is the same as $A+(-B)$; same circuit
	\item Operations do not depend on the operands' signs
	\item Range is asymmetric: $[-2^{n-1}, 2^{n-1}-1]$
	\item Two kinds of overflows 
\end{itemize}
\subsubsection{Sign extension}
Process of converting from a smaller to a larger representation.
MSB is extended to all the new bits.
\subsubsection{Overflow detection}
\begin{enumerate}
	\item If numbers with \textbf{opposite signs} are \textbf{added}, no overflow is possible.
	\item If numbers with \textbf{identical signs} are \textbf{substracted}, no overflow is possible.
\end{enumerate}
\begin{tabular}{| c | c | c | c |}
	\hline
	Operation & Operand A & Operand B & Result of Overflow\\
	\hline
	$A + B$ & $\geq 0$ & $\geq 0$ & $<0$\\
	\hline
	$A + B$ & $< 0$    & $< 0$    & $\geq 0$\\
	\hline
	$A - B$ & $\geq 0$ & $< 0$    & $<0$\\
	\hline
	$A - B$ & $< 0$    & $\geq 0$ & $\geq 0$\\
	\hline
\end{tabular}
\subsection{Shifting}
Moving the bits of a number left or right.
\begin{itemize}
	\item left shifts: \begin{itemize}
		\item zeros fill in the empty bits
		\item equivalent to multiplication by $2$
	\end{itemize}
	\item right shifts \begin{itemize}
		\item logical shift: fill with zero, for non-numerical data
		\item arithmetic shift: fill with MSB, for two's complement numbers
		\item equivalent to integer division by $2$
	\end{itemize}
\end{itemize}
\subsection{Floating point numbers}
\subsubsection{Normalised scientific notation}
All floating point binary numbers are represented in the form
\begin{align*}
	(-1)^S 1.a_1a_2\cdots a_n \cdot 2^E.
\end{align*}
Advantages:
\begin{itemize}
	\item Simplifies machine representation.
	\item Simplifies comparisons.
	\item More compact for very small/large numbers.
\end{itemize}
\subsubsection{IEEE 754 Floating Point standard}
32 bit:
\begin{tabular}{| l | l | l | l |}
	\hline
	word length & sign ($S$) & exponent ($E$) & mantissa ($M$)\\
	\hline
	\hline
	32 bit & 1 bit & 8 bits & 23 bits\\
	\hline
	64 bit & 1 bit & 11 bits & 52 bits\\
	\hline
\end{tabular}\\\\
This results in the number
\begin{align*}
	(-1)^S \times (1.M) \times 2^{E-127}.
\end{align*}
\subsection{Characters}
\subsubsection{ASCII}
\begin{itemize}
	\item most common
	\item each character is one byte (just 256 characters)
\end{itemize}
\subsubsection{Unicode}
\begin{itemize}
	\item used by Java
	\item two bytes per character
	\item enough for all languages on earth
\end{itemize}
\subsubsection{Length}
\begin{itemize}
	\item variable length
	\item computer needs to know where it ends
	\item options:
	\begin{itemize}
		\item last character is \T{NULL} (C)
		\item length is stored with the string itself (Java)
		\item stored in separate variable 
	\end{itemize}
\end{itemize}
\section{Design Principles}
\begin{enumerate}
	\item Simplicity favours regularity.
	\item Smaller is faster.
	\item Good design demands good compromises.
	\item Make the common case fast.
\end{enumerate}
\section{MIPS ISA}
\begin{definition}
	The \textbf{instruction set architecture} (ISA) is the interface between
	the software and the hardware.
	\begin{itemize}
		\item Collection of all machine instructions recognised by
					a particular processor.
		\item privilege levels, memory managment, etc.
		\item abstracts away implementation details away from the user
		\item enables multiple implementations of the same ISA
	\end{itemize}
\end{definition}
\begin{definition}
	\textbf{Assembly language} is a symbolic representation of machine instructions
	\begin{itemize}
		\item makes it easy for humans to read and write machine code
		\item 1-to-1 mapping between a machine instructions and a corresponding
			    assembly instruction
	\end{itemize}
\end{definition}
\subsection{Instructions}
\begin{itemize}
	\item Separate instructions to \textbf{access} data in memory \& operate on it.
\end{itemize}

\begin{tabular}{| l | l | l | l |}
	\hline
	Category & Instruction & Example & Meaning	\\
	\hline
	\hline
	Arithmetic & add & \T{add \$s1,\$s2,\$s3} & \T{\$s1 = \$s2 + \$s3} \\
	\hline
	Arithmetic & sub & \T{sub \$s1,\$s2,\$s3} & \T{\$s1 = \$s2 - \$s3} \\
	\hline
\end{tabular}
\subsection{Fields}
\begin{itemize}
	\item \textbf{op}: Basic operation of the instruction
	\item \textbf{rs}: The first register source operand
	\item \textbf{rt}: The second register source operand
	\item \textbf{rd}: The register destination operand
	\item \textbf{shamt}: Shift amount
	\item \textbf{funct}: Function
\end{itemize}
\newcommand{\cellw}{1.3cm}	
\begin{tabular}{l l}
	\textbf{R-type:} &
	\begin{tabular}{| p{\cellw} | p{\cellw} | p{\cellw} | p{\cellw} | p{\cellw} | p{\cellw} | p{\cellw} |}
		\hline
		op & rs & rt & rd & shamt & funct \\
		\hline 
		6 bits & 5 bits & 5 bits & 5 bits & 5 bits & 6 bits\\
		\hline	
	\end{tabular}\\\\
	\textbf{I-type:} &
	\begin{tabular}{| p{\cellw} | p{\cellw} | p{\cellw} | p{\cellw} p{\cellw} p{\cellw} |}
		\hline
		op & rs & rt & address & & \\
		\hline
		6 bits & 5 bits & 5 bits & 16 bits & & \\
		\hline
	\end{tabular}\\\\
	\textbf{J-type:} &
	\begin{tabular}{| p{\cellw} | p{\cellw} p{\cellw} p{\cellw} p{\cellw} p{\cellw} |}
		\hline
		op & address & & & & \\
		\hline
		6 bits & 26 bits & & & & \\
		\hline
	\end{tabular}
\end{tabular}
\subsection{Procedures}
Should follow the following steps:
\begin{enumerate}
	\item Place parameters in a place where the procedure can access them.
	\item Transfer control to the procedure.
	\item Acquire the storage resources needed for the procedure.
	\item Perform the desired task.
	\item Place the result value in a place where the calling program can access it.
	\item Return control to the point of origin.
\end{enumerate}
The allocated registers are:
\begin{itemize}
	\item \T{\$a0-\$a3}: argument registers to pass parameters
	\item \T{\$v0-\$v1}: two value registers in which to return values
	\item \T{\$ra}: return address register to return to the point of origin
\end{itemize}
\subsection{Addressing}
\subsubsection{Register addressing}
Operands are registers.\\ Example: \T{add \$v0,\$a0,\$a1}.
\subsubsection{Base addressing}
Operand is a memory location whose address is the sum of a register and a constant in the instruction.\\
Example: \T{add 0(\$a0),4(\$a0),8(\$a0)}
\subsubsection{Immediate addressing}
Operand is a constant within the instruction.\\
Example: \T{addi \$v0,\$v0,2}
\subsubsection{PC-relative addressing}
Address is the sum of the PC and a constant in the instruction.\\
Example: \T{beq \$a0,\$a1,L1}
\subsubsection{Pseudodirect addressing}
The 26-bits of the address are concatenated with the upper 4 bits of the PC.\\
Example: \T{j L1}
\subsection{Idioms}
\subsubsection{Conditionals}
\textbf{Simple equality:}
\begin{minted}{C}
if (a == b) {
	a = a + b
}
\end{minted}
Assume \T{a} is in \T{\$t0} and \T{b} is in \T{\$t1}.
\begin{verbatim}
      bne      $t0,$t1,Exit
      add      $t0,$t1,$t0
Exit: # more code
\end{verbatim}
\textbf{\T{max(a,b)} function:}
\begin{minted}{C}
if (a > b) {
	c = a
} else {
	c = b
}
\end{minted}
Assume \T{a,b,c} are in \T{\$t0-\$t2}.
\begin{verbatim}
       slt $t3,$t1,$t0
       beq $t3,$zero,ELSE
       add $t2,$t0,$zero
       j ENDIF
ELSE:  add $t2,$t1,$zero
ENDIF: 
\end{verbatim}
\subsubsection{Loops}
\subsubsection{Procedures}
\textbf{Pushing/Poppping values:}
\begin{verbatim}
push: li  $t0,4
      sub $sp,$sp,$t0
      sw  $v0,0($sp)
pop:  lw  $v0,0($sp)
      li  $t0,4
      add $sp,$sp,$t0
\end{verbatim}
\section{Assembler, Linker and Loader}
To run a set of \emph{pseudoinstructions}, you need three programs:
\begin{enumerate}
	\item Assembler: Turns human readable assembly into machine code.
	\item Linker: Turns machine code module and library routines into executable.
	\item Loader: Loads executable into memory and starts execution.
\end{enumerate}
\subsection{Assembler}
\begin{enumerate}
	\item expands syntactic sugar (e.g. \T{move}, \T{blt}, ...)
	\item validates references (and replaces big branches)
	\item converts instructions to binary
\end{enumerate}
The output of the assembler is called an \emph{object file}. A Unix object file contains
\begin{enumerate}
	\item object header
	\item text segment
	\item data segment
	\item relocation information
	\item symbol table
	\item debugging information
\end{enumerate}
More info at \emph{P\&H, Section 3.9, Page 157}.
\subsection{Linker}
\begin{enumerate}
	\item Places code and data modules symbolically in memory.
	\item Determines the addresses of data and instruction labels.
	\item Patches both the internal and external references.
\end{enumerate}
More info at \emph{P\&H, Section 3.9, Page 158}.
\subsection{Loader}
\begin{enumerate}
	\item Reads header to determine size of text and data segments.
	\item Creates address space large enough for the text and data.
	\item Copies the instructions and data into memory.
	\item Copies the parameters (if any) to the main program onto the stack.
	\item Initialises machine registers and sets stack pointer.
	\item Jumps to start-up routine. When \T{main} exits, returns with \T{exit} system call.
\end{enumerate}
\section{Logic design overview}
\subsection{Binary digital logic circuits}
\begin{itemize}
	\item Two voltage levels \begin{itemize}
		\item built from transistors
		\item analog circuits not very suitable for generic computing
		\item digital logic with more than two states is not practical 
	\end{itemize}
    \item types of circuits \begin{itemize}
		\item combinational logic: outputs depend only on inputs
		\item sequential logic: outputs depend on inputs and state
	\end{itemize}
\end{itemize}
\subsection{Gates}
\begin{itemize}
	\item AND gate: $O = I_1 \wedge I_2$
	\item OR gate: $O = I_1 \vee I_2$
	\item NOT gate: $O = \neg I$
	\item NOR gate: $O = \neg(I_1 \vee I_2) = \neg I_1 \wedge \neg I_2$
	\item NAND gate: $O = \neg(I_1 \wedge I_2) = \neg I_1 \vee \neg I_2$.
\end{itemize}
Sets of functional complete gates
\begin{itemize}
	\item NOT, OR, AND
	\item NAND
	\item NOR
\end{itemize}
\begin{definition}
	The multiplexer $z:\Z_2^3\to\Z_2$ is defined as
	\begin{align*}
		z(i_0,i_1,c) = \begin{cases}
			i_0 &\text{iff }c=0\\
			i_1 &\text{iff }c=1
		\end{cases}
	\end{align*}
	In terms of boolean expression, $z$ is equivalent to the following 
	\begin{align*}
		z(i_0,i_1,c) = \neg c i_0 \vee ci_1.
	\end{align*}
\end{definition}
\subsection{Modules}
Because building circuits for many inputs is complicated, we need modules.
\begin{itemize}
	\item Full adder: $f:\Z_2^3\to\Z_2^2$\begin{itemize}
		\item $f_s(a,b,c_{in})=\bar{a}\bar{b}c\vee \bar{a}b\bar{c} \vee a\bar{b}\bar{c} \vee abc$
		\item $f_{c_{out}}(a,b,c_in)=bc\vee ac\vee ab$
	\end{itemize}
	\item Ripple carry adder (n-bit): Chain of n full adders
\end{itemize}
\subsection{Propagation delay}
\begin{definition}
	\textbf{Propagation delay} is the delay between input signal
	change and output signal change at the other end.
\end{definition}
Delay depends on
\begin{itemize}
	\item technology,
	\item delay through each gate,
	\item number of gates driven by a gates output.
\end{itemize}
$\Rightarrow$ 65 gates are necessary to compute the final bit of the sum.
\subsection{Sequential logic circus}
\begin{itemize}
	\item Output depends on current and (some of the) past inputs, i.e. the circuit has memory
	\item sequences of inputs generate sequences of outputs $\Rightarrow$ \textbf{sequential logic}
\end{itemize}
Simplest memory element: $O_t = I_t \vee O_{t-1}$ where $O_{t-1}$ is the feedback from the last
computation. 
\subsection{Memory}
SR Latch:
\begin{itemize}
	\item two NOR gates with each others outputs as input
	\item two inputs: SET and RESET to change state
	\item if neither SET nor RESET are set, the previous state is remembered
\end{itemize}
Problem: Different paths may have different delays. This leads to invalid outputs, i.e. glitches.
\subsection{Timing of events}
\begin{itemize}
	\item State can only change at times synchronised to an external signal, the \textbf{clock}
	\item clock signal is combined with circuit (AND) right before the output
\end{itemize}
\textbf{Writing SR latch (D latch)}:
\begin{itemize}
	\item single input $D$, $R=\neg D$ and $S=D$
	\item clock before inputs to SR latch
	\item behaviour: \begin{itemize}
		\item $Q$ does not change when clock is $0$
		\item $Q$ can change while clock is $1$
	\end{itemize}
\end{itemize}
\textbf{Edge-triggered D flip-flop}:
\begin{itemize}
	\item on a \textbf{positive clock edge}, $D$ is propagated to $Q$
\end{itemize}
\textbf{Register}:
\begin{itemize}
	\item tie multiple $D$ flip-flops together using a common clock
\end{itemize}
\begin{definition}
Difference between latch and flip flop:
\begin{enumerate}
	\item A latch is \textbf{level triggered}.
	\item A flip flop is \textbf{edge triggered}.
\end{enumerate}
\end{definition}
\section{Processor Design}
\subsection{Measuring processor speed}
\begin{theorem}
	\label{exectime}
	For any program we find 
	\begin{align*}
		\text{exectution time} 
		= \frac{\text{instruction count} \times \text{cycle time}}{\text{clock frequency}}.
	\end{align*}
\end{theorem}
\subsection{Main processor functions}
\begin{itemize}
	\item Fetch instructions from \textbf{instruction memory}
	\item Read the \textbf{register} operands
	\item Use the \textbf{ALU} for computation
	\item Acces \textbf{data memory} for load/store
	\item Store the result of computation or loaded data into the destination \textbf{register}
	\item Update the \textbf{Program Counter (PC)}
\end{itemize}
\subsection{Single-cycle}
\subsubsection{Fetch}
\begin{itemize}
	\item PC value into \textbf{read address} of instruction memory
	\item instruction value (32-bit word) out of instruction memory
\end{itemize}
\subsubsection{Update the PC}
\begin{itemize}
	\item actually the first step
	\item write $\texttt{PC}=\texttt{PC}+4$ immediately
	\item this is \textbf{concurrent} with everything else, but clock stops the PC output from changing 
\end{itemize}
\subsubsection{R-Format Instructions}
\begin{enumerate}
	\item Read two register operands
	\item Perform arithmetic/logical operation
	\item Write register result
\end{enumerate}
\subsubsection{Load/Store Instructions}
\begin{enumerate}
	\item Read register operands
	\item Calculate address using 16-bit offset
	\item Read (for load) or write (for store) the memory
	\item Load only: update destination register
\end{enumerate}
\subsubsection{Branch Instructions}
\begin{enumerate}
	\item Read register operands
	\item Compare operands \begin{itemize}
		\item use ALU, subtract and check ALU's Zero output 
	\end{itemize}
	\item Calculate target address \begin{itemize}
		\item sign-extend the immediate
		\item shift left 2 places
		\item add to $\texttt{PC}+4$
	\end{itemize}
\end{enumerate}
\subsubsection{Handling Merging Wires}
\begin{itemize}
	\item splitting wires is fine, same voltage on both outputs
	\item mergin wires is bad, different voltages \Rightarrow short circuit!
	\item multiplexor required to choose between inputs
	\item this requires a control input
\end{itemize}
\subsubsection{Control Unit}
\begin{itemize}
	\item controls all the multiplexors
	\item not every instruction needs specific values for all control values
	\item irrelevant states are called \textbf{Don't Care}
	\item separate \textbf{ALU control} to handle ALU operation mode
\end{itemize}
\subsection{Multi-cycle}
\begin{itemize}
	\item more than one cycle per instruction
	\item generalise actions within each cycle
	\item reuse common set of datapath and control components
\end{itemize}
Components:
\begin{itemize}
	\item single memory
	\item single ALU
	\item registers
\end{itemize}
\textbf{Data required in subsequent cycles must be stored somewhere.}
\begin{itemize}
	\item used by subsequent instructions: registers \& memory
	\item used by current instruction: special registers (not visible to programmer) 
\end{itemize}
\subsubsection{Process}
\textbf{Cycle 1:} Fetch (access memory)
\begin{verbatim}
	IR <= Mem[PC]
	PC <= PC+4
\end{verbatim}
\textbf{Cycle 2:} Decode and read
\begin{verbatim}
	A      <= Reg[IR[25:21]]
	B      <= Reg[IR[20:16]]
	ALUOut <= PC+sgnext(IR[15:0]<<2)
\end{verbatim}
\textbf{Cycle 3:}
\begin{enumerate}
	\item R-type arithmetic/logical instruction \begin{verbatim}
		ALUOut <= A op B
	\end{verbatim}
	\item Immediate arithmetic or memory access \begin{verbatim}
		ALUOut <= A + sgnext(IR[15:0])
	\end{verbatim}
	\item Branch completion \begin{verbatim}
		if (cond) PC <= ALUOut
	\end{verbatim}
	\item Jump completion \begin{verbatim}
		PC <= {PC[31:28],IR[25:0],2'b00}
	\end{verbatim}
\end{enumerate}
\textbf{Cycle 4:}
\begin{enumerate}
	\item R-type arithmetic/logical completion \begin{verbatim}
		Reg[IR[15:11]] <= ALUOut
	\end{verbatim}
	\item Memory access (load) \begin{verbatim}
		MDR <= Mem[ALUOut]
	\end{verbatim}
	\item Memory access (store) \& completion \begin{verbatim}
		Mem[ALUOut] <= B
	\end{verbatim}
\end{enumerate}
\textbf{Cycle 5:} Load completion
\begin{verbatim}
	Reg[IR[20:16]] <= MDR
\end{verbatim}
\subsubsection{Control Unit}
FSM with state sequences based on op-code. (cf. slides)
\subsubsection{Effect \& Limits}
The multi-cycle processor has the following effects on the factors in \emph{\ref{exectime}}:
\begin{itemize}
	\item instruction count: unchanged
	\item cycles per instruction: increased, 3-4 times (avg., depending on instruction)
	\item clock frequency: increased, 5 times
\end{itemize}
$\Rightarrow$ Faster exectution time, especially with many short instructions.\\\\
Problem: Atomic operations, i.e. operations that cannot be subdivided, exist and thus we cannot
repeat this pattern infinitely. Number of cycles per instruction in modern processors: 20-30.



\section{Memory Hierarchy}



\subsection{Requirements}


Programmers want:
\begin{itemize}
	\item large
	\item fast 
	\item random access
\end{itemize}
\Rightarrow not with a single kind of memory.


\subsection{Idea}


Use a combination of memory kinds
\begin{itemize}
	\item Smaller amounts of expensive but fast memory closer to the processor
	\item Larger amounts of cheaper but slower memory farther from the processor
\end{itemize}


\subsection{Why is it effective?}


\begin{definition}[Temporal Locality]
	A recently accessed memory location (instruction or data) is likely to be accessed again in the
	near future.	
\end{definition}
\begin{definition}[Spatial Locality]
	Memory locations (instructions or data) close to a recently accessed location are likely to be
	accessed in the near future.	
\end{definition}
\begin{theorem}
	Locality exists in programs because
	\begin{itemize}
		\item instructions are reused (loops, functions), and
		\item the program only works on a limited set of data (arrays, temporary variables, objects).
	\end{itemize}
\end{theorem}


\subsection{In a modern processor}


Small, fast \textbf{cache} next to a processor backed up by larger \& slower chache(s) and main
memory give the impression of a single, large, fast memory.

Addresses temporal locality:
\begin{itemize}
	\item If access data from slower memory, move it to faster memory
	\item If data in faster memory unused recently, move it to slower memory
\end{itemize}


\noindent Addresses spatial locality:
\begin{itemize}
	\item If need to move a word from slower to faster memory, move adjacent words.
	\item \textbf{blocks} \& \textbf{pages}: units of storage within the caches
\end{itemize}

\noindent Storage units:
\begin{itemize}
	\item registers: words (4-8 bytes)
	\item cache: blocks (16-128 bytes)
	\item main memory: pages (1KB-2MB) 
\end{itemize}

\subsection{Data transfers}


\begin{itemize}
	\item Software (compiler): Between registers and cache/main memory
	\item Software (OS): Between main memory and storage
	\item Hardware: Between main memory and cache 
\end{itemize}


\subsubsection{Hardware-managed transfers between levels}


\begin{itemize}
	\item Occurs between cache memory and main memory levels
	\item Programmer \& processor both oblivious to where data resides
	\item cache hardware manages transfers between levels \begin{itemize}
		\item automatic in response to memory accesses
		\item memory always has a copy of cached data
		\item cache data may be more recent
	\end{itemize}
\end{itemize}

\subsection{Caches}


\subsubsection{Terminology}

\begin{definition}
	A \textbf{block} is a unit of data stored in the cache. Typically 32-128 bytes.
\end{definition}
\begin{definition}
	A \textbf{hit} occurs when the desired data is found in the cache.
\end{definition}
\begin{definition}
	A \textbf{miss} occurs when the desired data cannot be found in the cache.
	\Rightarrow search continues at the next level of the memory.
\end{definition}
\begin{definition}
	The \textbf{hit rate} is the fraction of accesses that are hits at a given level of the memory hierarchy.
\end{definition}
\begin{definition}
	The \textbf{miss rate} is the fraction of accesses that are misses at a given level of the memory hierarchy.
\end{definition}
\begin{definition}
	\textbf{Allocation} is the placement of a new block into the cache, which typically results in an eviction
	of another block.
\end{definition}
\begin{definition}
	\textbf{Eviction} is the displacement of a block from the cache which commonly happens when a new block is
	allocated in its place.
\end{definition}

\subsubsection{Basics}

How to mapp 32-bit address to a much smaller memory?
\begin{itemize}
	\item a \textbf{tag} word, indicating the address of the main memory block it holds
	\item a \textbf{valid bit}, indicating the block is in use
\end{itemize}

\subsubsection{Fully Associative Cache}

\begin{itemize}
	\item correct cache block identified by matching tags
	\item byte offset selects word/byte within block
	\item address tag can potentially match tag of any cache block
\end{itemize}

\subsubsection{Cache Replacement}

\begin{definition}
	\textbf{Least Recently Used} is a replacement strategy where the cached block that has not been accessed
	for the longest time gets evicted.
\end{definition}
\begin{definition}
	\textbf{FIFO} is a replacement strategy where the cached blocks get evicted in the same order they are 
	allocated in.
\end{definition}

\subsubsection{Direct Mapped Cache}

\begin{itemize}
	\item Problem of fully-associative cache: search is slow or requires expensive CAM
	\item data can be store in \textbf{one location only}
	\item uses last $n$ bits of word-address
\end{itemize}

\subsubsection{Set Associative Cache}

\begin{itemize}
	\item split the cache into groups of $m$ blocks each (\textbf{m-way set-associative})
	\item a given block can only go into one set, but anywhere withing that set 
	\item compromise between DM and FA caches
	\item typical degree of associativity is 2-16
\end{itemize}

\subsubsection{Writing strategies}

\begin{definition}
	\textbf{Write through} is a strategy where both the memory and the cache
	are updated on a hit.
	\begin{itemize}
		\item good: memory and cache always synchronised
		\item bad: writes are slow
	\end{itemize}
\end{definition}

\begin{definition}
	\textbf{Write back} is a strategy where a cache block gets flagged as
	dirty once it has been written to. When a dirty block is replaced,
	it is written to memory
	\begin{itemize}
		\item good: writes are fast and generate little traffic
		\item bad: memory anc have stale data for some time
	\end{itemize}
\end{definition}

\begin{definition}
	\textbf{Write allocate} is a strategy where on a cache miss a block 
	is brought into the cache and written to.
	\begin{itemize}
		\item useful if no locality exists
	\end{itemize}
\end{definition}

\begin{definition}
	\textbf{Write no-allocate} is a strategy on a cache miss the data is
	written directly to memory and not brought to the cache.
	\begin{itemize}
		\item useful if no locality
		\item guarantees that cache and memory are synchronised
	\end{itemize}
\end{definition}


\subsection{Virtual Memory}


\subsubsection{Motivations}

\begin{enumerate}
	\item Limited capacity of main memory
	\item Safety of shared memory between applications
\end{enumerate}

\subsubsection{Idea}

\begin{itemize}
	\item each program thinks it owns the entire memory (\textbf{virtual address space})
	\item actual main memory is \textbf{physical address space}
	\item virtual addresses are translated on-the-fly to physical addresses
	\item translation is done by OS and HW
\end{itemize}

\subsubsection{Physical memory as a cache for VM}

\begin{itemize}
	\item virtual memory space can be larger than physical memory
	\item physical memory is a cache for virtual memory
	\item secondary storage backs the physical memory
\end{itemize}

\subsubsection{Paging}

\begin{definition}
	A cache line or block of VM is called a \textbf{page}.
	\begin{itemize}
		\item Simply page or virtual page for VM
		\item Page frame or physical page for physical memory
	\end{itemize}
\end{definition}
\begin{itemize}
	\item Typical page sizes are 4-16 KB
	\item Mapping is done through a per-program \textbf{page table}
\end{itemize}

\subsubsection{Address Translation}

\begin{itemize}
	\item virtual addresses consist of page number ($V$) and page offset ($O$)
	\item physical addresses consist of frame number ($F$) and page offset ($O$)
	\item page table translates $V$ to $F$ by maintaining an entry for every value of $V$
	\item a page table entry (PTE) for $V$ consists of status bits and $F$
\end{itemize}

\subsubsection{Moving pages to/from memory}

\begin{itemize}
	\item pages are allocated on demand 
	\item pages are replaced and swapped to disk when system runs out of free page frames
	\item access to a swapped-out page causes a \textbf{page-fault}
\end{itemize}
Status bits:
\begin{itemize}
	\item A: Access bit is set whenever a page is accessed and reset periodically
	\item M: Modified bit is set when a page is modified so desynchronised from disk
	\item R: Residence bit indicates whether the page is currently in physical memory
\end{itemize}

\subsubsection{Providing Protection}

\begin{itemize}
	\item each PTE can have permission bits \begin{itemize}
		\item W: read \& write
		\item R: read-only
		\item E: execute-only
	\end{itemize}
	\item per-process memory protection
	\item Important: Only OS can change page tables
\end{itemize}

\subsubsection{Translation Lookaside Buffer (TLB)}

\begin{itemize}
	\item small, fully-associative cache of PTEs \begin{itemize}
		\item Each TLB entry holds translation info
		\item Tag: $V$, Entry: $F$
	\end{itemize}
	\item small and fast table in hardware, located close to CPU
	\item when page not in TLB: access the page table and save the translation
	\item status bits: \begin{itemize}
		\item V indicates a valid entry
		\item D indicates whether page has been modified
		\item R, W, X permission bits
	\end{itemize} 
\end{itemize}

\section{Exceptions \& Processor Management}

\begin{definition}
	An \textbf{exception} is an event that interrupts the normal program flow
	and requires attention of the CPU outside of the running program.
\end{definition}

External:
\begin{itemize}
	\item not caused by program execution
	\item e.g., I/O interrupt
\end{itemize}

Internal:
\begin{itemize}
	\item caused by program execution
	\item e.g., \T{syscall}, TLB miss
\end{itemize}

\subsection{Intentional exceptions}

\begin{itemize}
	\item Use exception mechanism to requrest some OS functions
	\item MIPS uses \T{syscall}
	\item parameters are passed to the OS through registers
\end{itemize}

\subsection{Exception mechanism}

\begin{enumerate}
	\item Save the address of current instruction (into EPC)
	\item Transfer control to the OS at a known address
	\item Handle the exception
	\item Return to user program execution (instruction \T{eret})
\end{enumerate}

\subsection{Finding the exception handler}

Approach 1:
\begin{itemize}
	\item jump to predefined address
	\item use the \textbf{Cause register} to branch to right handler
	\item works well for \T{syscall}
\end{itemize}

Approach 2:
\begin{itemize}
	\item directly jump to a specific handler depending on the exception (\textbf{vectored interrupt})
	\item the interrupt signal comes from the "outside" via CPU pins
\end{itemize}

\subsection{Handling the exception}

\begin{itemize}
	\item determine required action
	\item if possible: take corrective action, use EPC to jump back
	\item otherwise: terminate program, report error
	\item \textbf{During the interrupt, not other interrupts should happen!}
\end{itemize}

\subsection{Protecting system resources}

\begin{itemize}
	\item OS mus guarantee safe and orderly accesses
	\item OS decides what's allowed
	\item exceptions are used to hand control over to the OS
\end{itemize}

\subsection{Kernel vs. User Mode Protection}

\begin{itemize}
	\item two CPU modes: \textbf{user} and \textbf{kernel}
	\item privileged instructions only executed in kernel mode
	\item kernel mode can only be entered through an exception
	\item \T{eret} returns to previous mode
\end{itemize}

Advantages of Dual Mode architecture:
\begin{itemize}
	\item guarantees OS handles dangerous program behaviour
	\item allows OS to stop interference between programs
	\item allows OS to limit resource accesses
	\item limits CPU time
\end{itemize}

\subsection{Time-Sharing the CPU}

\begin{itemize}
	\item Problem: I/O takes too long
	\item Solution: share CPU among several user processes
\end{itemize}

Managing Processes:
\begin{itemize}
	\item processes are managed by the OS kernel 
	\item scheduler chooses which process to run next
\end{itemize}

\subsection{Process States}

States:
\begin{itemize}
	\item \textbf{RUNNING}: process is currently running
	\item \textbf{READY}: process is not running, but could run if brought into CPU
	\item \textbf{BLOCKED}: process is not able to run (i.e. waiting on I/O)
\end{itemize}

Transitions:
\begin{itemize}
	\item \textbf{I/O REQ}: process initiates I/O
	\item \textbf{I/O COMP}: I/O finishes
	\item \textbf{DISPATCH}: Os moves processes into CPU and it starts executing
	\item \textbf{TIMEOUT}: process's \textbf{timeslice} is over
\end{itemize}

\begin{definition}
	The \textbf{PCB} is an OS data structure containing each process's information:
	\begin{itemize}
		\item PID
		\item state
		\item priority
		\item permissions
		\item ...
	\end{itemize}
\end{definition}

\subsection{Suspending and Resuming Processes}

\begin{itemize}
	\item Problem: Might not have enough physical memory for all processes
	\item Solution: Processes can be swapped out from memory to disk
\end{itemize}

\end{document}
