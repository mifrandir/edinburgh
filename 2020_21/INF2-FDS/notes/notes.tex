\documentclass{article}
\usepackage{notes-preamble}
\mkthms
\renewcommand{\bar}{\overline}
\begin{document}
\title{Foundations of Data Science (YEAR2)}
\author{Franz Miltz}
\maketitle
\tableofcontents
\pagebreak


\section{Statistical preliminaries}


\begin{definition}
	The \emph{sample mean} $\bar{x}$ for sample $x_1, x_2, ..., x_n$
	is defined as
	\begin{align*}
		\bar{x} = \frac{1}{n}\sum_{i=1}^n x_i.
	\end{align*}
\end{definition}
\begin{definition}
	The \emph{sample median} $\tilde x$ for a sample $x_1, x_2, ..., x_n$ is defined as 
	\begin{align*}
		\tilde x = \begin{cases}
			x_{(n+1)/2} 				   &\text{if $n$ is odd},\\
			\frac{1}{2}(x_{n/2}+x_{n/2+1}) &\text{otherwise}.
		\end{cases}.
	\end{align*}
\end{definition}
\begin{theorem}
	The relation of the mean $\bar x$ and the median $\tilde x$ can be inferred as follows
	\begin{enumerate}
		\item If a distribution is \emph{symmetric}, then $\bar x = \tilde x$
		\item If a distribution is \emph{positively skewed}, then $\bar x > \tilde x$
		\item If a distribution is \emph{negatively skewed}, then $\bar x < \tilde x$.
	\end{enumerate}
\end{theorem}
\begin{definition}
	The \emph{sample variance} $s_x^2$ of a sample $x_1, x_2, ..., x_n$ is defined as
	\begin{align*}
		s_x^2 = \frac{1}{n-1}\sum_{i=1}^n (x_i-\bar x)^2.
	\end{align*}
\end{definition}
\begin{definition}
	The \emph{sample standard deviation} $s_x$ of a sample $x_1, x_2, ..., x_n$ is defined as
	\begin{align*}
		s_x = \sqrt{s_x^2}.
	\end{align*}
\end{definition}
\begin{definition}
	The \emph{population variance} $\sigma_x^2$ of a population $x_1, x_2, ..., x_N$ is defined as
	\begin{align*}
		\sigma_x^2 =\frac{1}{N}\sum_{i=1}^N (x_i-\bar x)^2.
	\end{align*}
\end{definition}
\begin{definition}
	The \emph{population standard deviation} $\sigma_x$ of a population $x_1, x_2, ..., x_N$ is defined as
	\begin{align*}
		\sigma_x = \sqrt{\sigma_x^2}.
	\end{align*}
\end{definition}


\section{Linear Models}


\begin{definition}
	The \emph{sample covariance} $s_{xy}$ of a sample $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$
	is defined as
	\begin{align*}
		s_{xy} = \frac{1}{n}\sum_{i=1}^n (x_i - \bar x)(y_i - \bar y).
	\end{align*}
\end{definition}
Notes about the sample covariance:
\begin{enumerate}
	\item The units are $[x][y]$.
	\item Scaling the units linearly scales $s_{xy}$ linearly.
\end{enumerate}
\begin{definition}
	The \emph{correlation coefficient} $r$ of a sample $(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)$ is defined as
	\begin{align*}
		r = \frac{s_{xy}}{s_x s_y}.
	\end{align*}
\end{definition}
Properties about the correlation coefficient:
\begin{enumerate}
	\item $-1 \leq r \leq 1$
	\item $y=cx \Rightarrow |r|=1$
\end{enumerate}
\begin{definition}
	The standardised variable $z$ of the quantity $x$ is defined as
	\begin{align*}
		z_i = \frac{x_i-\bar x}{s_x}.
	\end{align*}
\end{definition}
Properties of the standardised variable:
\begin{enumerate}
	\item $\bar z = 0$,
	\item $s_z = 1$,
	\item dimensionless,
	\item covariance of two standardised variables is the same as correlation.
\end{enumerate}
\begin{definition}
	Let $y$ be a variable dependent on $x$ with $y=\beta_0 + \beta_1 x$. Then
	$\beta_0$ is the intercept and $\beta_1$ is the slope.
\end{definition}
\begin{definition}
	The distance of the line $(\beta_0,\beta_1)$ to a sample $(x,y)$ is definend as
	\begin{align*}
		f(\beta_0, \beta_1) = \sum_{i=1}^n (y_i -(\beta_0 + \beta_1 x_i))^2.
	\end{align*}
	The line $(\hat\beta_0, \hat\beta_1)$ is the one that minimises $f$.
\end{definition}
\begin{theorem}
	The closest line $(\hat\beta_0,\hat\beta_1)$ to a sample $(x,y)$ can be calculated with
	\begin{align*}
		\hat\beta_1&=\frac{\sum(x_i-\bar x)(y_i-\bar y)}{\sum(x_i-\bar x)^2},\\
		\hat\beta_0&=\bar y - \hat\beta_1\bar x.
	\end{align*}
\end{theorem}
Properties of the linear regression line:
\begin{enumerate}
	\item $(\bar x, \bar y)\in(\hat\beta_0, \hat\beta_1)$,
	\item $\hat\beta_1 = \frac{s_y}{s_x}r$.
\end{enumerate}
Properties of the regression line of standardised variables:
\begin{enumerate}
	\item $(0,0)\in(\hat\beta_0,\hat\beta_1)$,
	\item $\hat\beta_0=0,\hat\beta_1=r$,
	\item the predicted standardised $y$ is always closer to the mean than the standardised $x$.
\end{enumerate}
\begin{definition}
	Let $(\hat\beta_0,\hat\beta_1)$ be a regression line of $(x,y)$. Then the
	\emph{predicted value} $\hat y_i$ for each $x_i$ is defined as
	\begin{align*}
		\hat y_i = \hat\beta_0 + \hat\beta_1 x_i.
	\end{align*}
\end{definition}
\begin{definition}
	The differences $y_i - \hat y_i$ for each $i$ are called \emph{residuals}.
\end{definition}
Note on residuals from linear regression:
\begin{enumerate}
	\item Zero mean
	\item Zero correlation with independent variable $x$
	\item Zero correlation with the predicted values $\hat y$
\end{enumerate}
\begin{definition}
	The \emph{mean square error} is defined by
	\begin{align*}
		\mse = \frac{1}{n}\sum_{i=1}^n (y-\hat y)^2
	\end{align*}
	and the \emph{root mean square error} is given by $\rmse=\sqrt{\mse}$.
\end{definition}
\begin{definition}
	A measure of the total variance in $y$ before we know anything
	about $x$ is the \emph{total sum of squares (SST)}, which we define
	as the sum of squared deviations from the mean of $y$:
	\begin{align*}
		\sst = S_{yy} = \sum (y_i - \bar y)^2 = (n-1)s^2_y.
	\end{align*}
\end{definition}
\begin{definition}
	The \emph{sum of squared errors (SSE)} is defined
	\begin{align*}
		\sse = \sum (y_i -\hat y_i)^2.
	\end{align*}
\end{definition}
\begin{definition}
	The \emph{coeficient of determination} is defined
	\begin{align*}
		R^2 = 1-\frac{\sse}{\sst}.
	\end{align*}
\end{definition}
Notes on $R^2$:
\begin{itemize}
	\item $R^2$ is a measure of "goodness of fit"
	\item $R^2=1$ indicates that the model predicts the data perfectly
	\item $R^2=0$ indicates no predictive value
\end{itemize}


\section{Multiple regression}


\begin{definition}
	The process of predicting a dependent variable from multiple independent variables is called \emph{multiple regression}.
\end{definition}
\begin{definition}
	Suppose we have two independent variables $x^{(1)}$ and $x^{(2)}$ and one dependent variable $y$.
	The multiple regression model is then expressed as
	\begin{align*}
		y = \beta_0 + \beta_1 x^{(1)} + \beta_2 x^{(2)}.
	\end{align*}
\end{definition}
\begin{definition}
	Let $x^*_{ik}=x^{(k)}_i - \bar x^{(k)}$. Then the \emph{regressor matrix} $T$ is
	the $n\times K$ matrix defined as
	\begin{align*}
		T = \begin{pmatrix}
			x^*_{11} & x^*_{12} & \cdots & c^*_{1K}\\
			x^*_{12} & x^*_{22} & \cdots & c^*_{2K}\\
			\vdots & \vdots & \ddots & \vdots\\
			x^*_{1n} & x^*_{2n} &\cdots & c^*_{nK}
		\end{pmatrix}.
	\end{align*}
\end{definition}
\begin{definition}
	Let $y^*_i=y_i-\bar y$. Then the \emph{moment matrix} is defined as
	\begin{align*}
		X^T y = \begin{pmatrix}
			\sum x^*_{i1} y^*_i\\
			\vdots\\
			\sum x^*_{iK} y^*_i
		\end{pmatrix}
	\end{align*}
	where $y$ is the column vector containing all $y^*_i$.	
\end{definition}
\begin{definition}
	The \emph{covariance matrix} is defined as
	\begin{align*}
		S =\frac{1}{n-1}X^T X.
	\end{align*}
\end{definition}
\begin{theorem}
	To minimise
	\begin{align*}
		f(\beta_0, \beta_1, \beta_2) = \sum (y_i - (\beta_1 x_{i1}+\beta_2 x_{i2}))^2
	\end{align*}
	we require
	\begin{align*}
		\hat\beta_0 = \bar y - \beta_1\bar x^{(1)} - \beta_2\bar x^{(2)}
	\end{align*}
	and
	\begin{align*}
		\hat\beta = \begin{pmatrix}
			\hat\beta_1\\
			\hat\beta_2
		\end{pmatrix}
		= (X^T X)^{-1}X^T y.
	\end{align*}
\end{theorem}
\begin{definition}
	The \emph{interaction term model} for two independent variables $x^{(1)}$ and $x^{(2)}$ and one dependent variable $y$
	is defined as
	\begin{align*}
		y = \beta_0 + \beta_1 x^{(1)} + \beta_2 x^{(2)} + \beta_3 x^{(1)}x^{(2)}.
	\end{align*}
\end{definition}
Notes:
\begin{itemize}
	\item for $x^{(2)}\in (0,1)$ this is equivalent to two separate linear regressions
	\item we avoid having to create separate datasets
	\item makes regression on two continuous variables more precise
\end{itemize}
\begin{definition}
	If the number of variables is $k$ and the number of instances is $n$, the
	\emph{adjusted coefficient of determination} is given
	\begin{align*}
		R^2_a = 1 - \frac{n-1}{n-k-1}\frac{\sse}{\sst}.
	\end{align*}
\end{definition}
Note: Adjustment is useful because finding a good fit becomes easier with more variables. We don't want this to affect $R^2$.


\section{Principle Component Analysis}


\begin{definition}
	The \emph{variance along the $i$th axis} is given by $S_{ii}$ where $S$ is the
	covariance matrix.
\end{definition}
\begin{definition}
	Given a unit vector $\vec p$ the \emph{component score} $t_i$ of a data point
	$\vec x_i$ is defined as
	\begin{align*}
		t_i = {\vec p}^{T} \vec x_i.
	\end{align*}
\end{definition}
\begin{definition}
	The \emph{variance of a component score} $t^{(i)}$ is
	\begin{align*}
		s_t^2 = \frac{1}{n-1}\sum_{i=1}^n t_i^2.
	\end{align*}
	This can be rewritten as
	\begin{align*}
		s^2_t = \vec p^T S\vec p.
	\end{align*}
\end{definition}
\begin{theorem}
	The $i$th principal component of a dataset with the $D\times D$ covariance
	matrix $S$ is the eigenvector corresponding to the $i$th largest eigenvalue 
	of $S$.
\end{theorem}
\begin{proposition}
	The fraction of the total variance explained by the $i$th principal component
	is 
	\begin{align*}
		\frac{\lambda_i}{\sum_{j=1}^D \lambda_j}
	\end{align*}
	where $\lambda_j$ is the eigenvalue corresponding to the $j$th prinicipal
	component.
\end{proposition}

\begin{theorem}
	Given component scores $\vec t^{(i)}$ and a set of components $\vec p_j$,
	the original data point $\vec x_i$ may be reconstructed as
	\begin{align*}
		\vec x_i = \sum_j t^{(i)}_j \vec p_j.
	\end{align*}
	Note: If only a subset of the principle components is chosen, this
	reconstruction is likely to be in accurate.
\end{theorem}


\section{Clustering, unsupervised and supervised learning}


\begin{definition}
	\emph{Cluster analysis} aims to partition a data set into meaningful or useful
	groups, based on distances between data points.
\end{definition}
\begin{definition}
	Classification is a \emph{supervised learining} process: there is a training
	set in which each dat a item has a label.
\end{definition}
\begin{definition}
	Clustering is an \emph{unsupervised learning} process in which the training
	set does not contain any labels. The aim of a clustering algorithm is to group
	such a data set into clusters, based on the unlabelled data alone.
\end{definition}
\begin{definition}
	Clustering may be used to compress data by representing each data itme
	in a cluster by a single cluster \emph{prototype}, typically at the centre
	of the cluster.
\end{definition}

\subsection{Types of clustering}

\begin{definition}
	\emph{Hierarchical clustering} forms a tree of nested clusters in which, at
	each level in the tree, a cluster is the union of its children.
\end{definition}
\begin{definition}
	\emph{Partitional clustering} divides the data into a fixed number of
	non-overlapping clusters, with each data point assigned to exactly one
	cluster.
\end{definition}

\subsection{K-means}

\subsubsection{Aim}

Dividing a set of $D$-dimensional data points into $K$ clusters.

\subsubsection{Algorithm}

\begin{enumerate}
	\item Initialise $K$ cluster centres, $\{\vec m_k\}^K_1$
	\item While not converged: \begin{enumerate}
		\item Assign each data vector $\vec x_i$ ($i\in[1,n]$) to the closest cluster centre
		\item Recompute each cluster mean as the mean of the vectors assigned to that cluster
	\end{enumerate}
\end{enumerate}
\begin{theorem}
	Let $C_k$ be the set of points in cluster $k$. Then the mean of cluster $k$
	is 
	\begin{align*}
		\vec m_k=\frac{1}{\abs{C_k}}\sum_{i\in C_k}\vec x_i.
	\end{align*}
\end{theorem}
\begin{definition}
	The distance between two points $\vec x$ and $\vec y$ in Euclidean space
	is given by
	\begin{align*}
		d(\vec x, \vec y) = \vabs{\vec x - \vec y}=\sqrt{\sum_{j=1}^D(x_j-y_j)^2}.
	\end{align*}
\end{definition}
There are several possible ways to \emph{initialise} the cluster centres, including:
\begin{itemize}
	\item random data points
	\item means of random partitions of the input
	\item data points with extreme values
	\item perturb mean of data set 
\end{itemize}
\begin{definition}
	\emph{Convergence} is reached when the assignment of points to clusters
	does not change after an iteration.
	\begin{itemize}
		\item convergence is guranteed
		\item number of iterations up to convergence is not guranteed
		\item there may be \emph{multiple converging solutions}
	\end{itemize}
\end{definition}

\subsubsection{Evaluation}

To find best solution: Repeat with different initialisations and pick solution
with the lowest error.
\begin{definition}
	The \emph{mean squared error function} may be used to compare two clusterings
	each with $K$ clusters. Let $C_k$ be the set of points in the $k$th cluster.
	Then the MSE is
	\begin{align*}
		E = \frac{1}{n}\sum_{k=1}^K \sum_{i\in C_k} \vabs{\vec x_i - \vec m_k}^2
	\end{align*}
	where $\vec m_k$ is the centre of cluster $k$ and $n$ is the number of data
	points in total.
\end{definition}

\subsubsection{Shortcomings}

\begin{itemize}
	\item dependent on the scale of data
	\item large clouds can pull small clusters off-centre
\end{itemize}

\subsubsection{Variants}

\begin{itemize}
	\item Batch: update centres after assigning all the values
	\item Online: update centres after assigning individual values 
\end{itemize}


\section{Introduction to supervised learning}


\begin{definition}
	A \emph{classifier} is a function that takes a feature vector $\vec x$
	and returns a class $c$ where $c$ is a member of a set $C$.
\end{definition}
\begin{definition}
	A \emph{decision boundary} partitions the input space between two
	classifications.
\end{definition}

\subsection{Construction classifiers using unsupervised learning}

To construct the classifier automatically we need
\begin{enumerate}
	\item a set of training data containing feature vectors and their labels
	\item an algorithm that we train using the training data
	\item \emph{hyperparameters}, number that control how the algorithm learns and predicts
\end{enumerate}
This is referred to as \emph{supervised learning}, since the label for a training
vector acts as supervision for the classifier when it is learning from
training data.

\subsection{Regression as supervised learning}

\begin{itemize}
	\item labels are not categories but independent variable
	\item tries to predict label for unknown input
\end{itemize}

\subsection{Nearest neighbour classification}

\subsubsection{Procedure}

\begin{itemize}
	\item requires a distance measure
	\item for each new input we return the label of the nearest point in the training data
\end{itemize}

\subsubsection{Decision boundaries}
\begin{itemize}
	\item \emph{Voronoi diagram}
	\item piecewise linear
\end{itemize}

\subsubsection{Evaluation}

\begin{definition}
	A suitable error function for classification is the number of items
	that are misclassified. The classification error is often expressed 
	as the percentage of the total number of items that is misclassified,
	the \emph{error rate}.
\end{definition}
\begin{theorem}
	For one-nearest neighbour classification the error rate when we consider
	members of the training sset is $0$.
\end{theorem}
\begin{definition}
	To evaluate our algorithm, we split the available data into the
	\emph{training set} (70\%) and the \emph{testing set} (30\%). No data points
	from the testing set are used in training.
\end{definition}
\begin{definition}
	The \emph{training set error rate} is the percentage of misclassifications
	that the classifier makes on the training set after the learning 
	algorithm has been applied.\\
	The \emph{testing set error rate} refers to errors made by the classifier
	on the testing set.
\end{definition}

\subsection{$k$-Nearest neighbour classification}

\subsubsection{Principle}

\begin{itemize}
	\item We consider the $k$ closest points.
	\item If the classification is tied, we choose randomly.
\end{itemize}

\subsubsection{Decision boundaries}

\begin{itemize}
	\item susceptible to noise for small $k$
	\item smoother with large $k$
\end{itemize}

\subsubsection{Algorithm}

For an unseen example $\vec x$:
\begin{enumerate}
	\item Compute the $n$ distances $d_i=d(\vec x, \vec x_i)$ and the features
		  of each training example $x_i$, $i\in[0,n]$.
    \item Sort the distances from lowest to highest and find the indices $i_1,...,i_k$ of the $k$ lowest values of $d_i$.
    \item Find the classes that belong to the closest points.
    \item Count the votes for each class and return the one with the largest number.
    \item If there is a tie, choose randomly, or look at the $k+1$th neighbour to resolve it.
\end{enumerate}

\subsubsection{Choosing $k$}

To find the hyperparameter $k$, we need a validation set. So we split
the input data into three parts:
\begin{enumerate}
	\item training data (50\%)
	\item validation data (25\%)
	\item testing data (25\%)
\end{enumerate}

\subsubsection{Efficiency}
\begin{itemize}
	\item training is very efficient because no processing is done
	\item testing is very inefficient and impractical for large data sets
\end{itemize}

Optimisation: Managing data better, e.g. $k$-d trees.


\section{Randomness, Sampling and Simulation}


\subsection{Statistical Inference}

\begin{definition}
	\emph{Inferential statistics} is the process of drawing conclusions
	about quantities that are not observed.
\end{definition}

\subsection{Sampling, statistics and simulations}

\begin{definition}
	\emph{Sampling} from probability distributions and from sets of discrete
	items is a prerequisite for statistical simulations.
\end{definition}

\begin{definition}
	A \emph{random sample} of size $n$ from either a continuous probability
	distribution or a finite population of $N$ items is comprised of
	the independente, identically distributed random variables $X_1,...,X_n$.
\end{definition}

\begin{definition}
	A \emph{statistic} is any quantity whose value can be calculated from
	sample data.
\end{definition}

\subsection{The distribution of the sample mean of large samples}

\begin{definition}
	The \emph{standard error in the mean} (SEM) is the standard deviation
	of the mean $\sigma_{\bar x}$. It may be calculated with
	\begin{align*}
		\sigma_{\bar x} = \sigma / \sqrt{n}.
	\end{align*}
\end{definition}

\begin{theorem}[Central Limit Theorem]
	Let $X_1,...,X_n$ be a random sample from a distribution with mean
	$\mu$ and variance $\sigma^2$. Then, in the limit $n\to\infty$ the
	standardised mean $((\bar X - \mu) / (\sigma / \sqrt{n}))$ and
	standardised total $((T_0 - n\mu)/(\sqrt{n}\sigma))$ have a normal
	distribution. That is
	\begin{align*}
		\lim_{n\to\infty}P\left(\frac{\bar X - \mu}{\sigma / \sqrt{n}}\leq z\right)
		= P(Z\leq z) = \Phi(z)
	\end{align*}
	and
	\begin{align*}
		\lim_{n\to\infty}P\left(\frac{\bar T_0-n\mu}{\sqrt{n}\sigma\leq z}\right)
		= P(Z\leq z) = \Phi(z)
	\end{align*}
	where $\Phi$ is the cumulative distribution function of a normal distribution
	with mean $0$ and standard deviation $1$.
\end{theorem}

\begin{theorem}
	Let $X_1, ..., X_n$ be a random sample from a distribution with mean
	$\mu$ and variance $\sigma^2$. As the number of observations $n$
	increases, the expected value of the sample mean remains $\E[\bar X]=\mu$,
	but the expected variance $\V[\bar X]=\E[(\bar X - \mu)^2]\to 0$.
\end{theorem}


\section{Estimation}


\subsection{Point estimation}

\begin{definition}
	Let $\vartheta$ be a parameter and $\hat\vartheta$ its estimator.
	Then the \emph{bias} of a particular estimation as
	\begin{align*}
		\text{bias}=\E(\hat\vartheta-\vartheta)=\E(\hat\vartheta)-\vartheta.
	\end{align*}
	If for all values of $\vartheta$,
	\begin{align*}
		\E(\hat\vartheta)-\vartheta = 0
	\end{align*}
	the estimator is \emph{unbiased}.
\end{definition}

\begin{definition}
	The \emph{mean sqaured error} of an estimator $\vartheta$
	is defined as
	\begin{align*}
		\text{MSE} = \E((\hat\vartheta-\vartheta)^2).
	\end{align*}
\end{definition}

\begin{theorem}
	Let $\vartheta$ be a parameter and $\hat\vartheta$ its estimator.
	Then
	\begin{align*}
		\text{MSE}=\text{variance}+(\text{bias})^2.
	\end{align*}
\end{theorem}

\begin{definition}
	The \emph{standard error of an estimator} $\sigma_{\hat\varepsilon}$
	is defined as
	\begin{align*}
		\sigma_{\hat\varepsilon}=\sqrt{\V(\hat\vartheta)}
	\end{align*}
\end{definition}

\begin{definition}
	The \emph{standard error in the mean} is defined as
	\begin{align*}
		\hat\sigma_{\hat\mu}=
		\begin{cases}
			\sigma/\sqrt{n} &\text{if $\sigma$ is known},\\
			S/\sqrt{n} &\text{otherwise}
		\end{cases}
	\end{align*}
	where $S$ is the sample standard deviation.	
\end{definition}

\subsection{Confidence intervals}

\begin{definition}
	Let $\alpha\in(0,1)$. Then a corresponding \emph{confidence interval}
	is an interval $(\hat\vartheta-a\hat\sigma_{\hat\vartheta}, \hat\vartheta+b\hat\sigma_{\hat\vartheta})$
	that has the chance $1-\alpha$ of containing the parameter $\vartheta$.
	I.e.
	\begin{align*}
		\P\left(-b < \frac{\hat\vartheta-\vartheta}{\hat\sigma_{\hat\vartheta}}<a\right) = 1-\alpha.
	\end{align*}
\end{definition}

\subsection{Bootstrapping}

\textbf{Bootstrap procedure for finding the mean}\\
Consider a sample of $n$ data points with mean
$\lneg x$. We take $B$ bootstrap samples.
Then the procedure is
\begin{enumerate}
	\item For $j\in[1,B]$ \begin{enumerate}
		\item Take sample $x^*$ of size $n$ from the sample \emph{with replacement}
		\item Compute the sample mean of the new sample $\lneg{x_j^*}$
	\end{enumerate} 
	\item Find the centiles of the distribution at $100\alpha/2$ and $100(1-\alpha/2)$
		  by arranging the sample means $\lneg x^*_j$ in ascending order and pick
		  $\lneg x^*_j$ at $$k=\alpha(B+1)/2$$ to be the lower end of the CI and pick
		  $\lneg x^*_j$ at $$k=B-\alpha(B+1)/2$$ to be the upper end of the CI.
    \item We can compute the boostrap estimator fo the variance of the mean \begin{align*}
		s^2_{\text{boot}} = \frac{\sum_{j=1}^B(\lneg x_j^*-\lneg x)^2}{B-1}
	\end{align*}
\end{enumerate}

\subsection{Confidence intervals on the mean for small samples}

\begin{definition}
	The $t$ distribution with $v$ degrees of freedom is given by the
	probability density function
	\begin{align*}
		p_v(t)=\frac{1}{\sqrt{\pi v}}\frac{\Gamma((v+1)/2)}{\Gamma(v/2)}\frac{1}{(1+t^2/v)^{(v+1)/2}}.
	\end{align*}
\end{definition}

\begin{theorem}
	Let $\lneg X$ be random sample of size $n$ from a normal distribution
	with mean $\mu$. Then the random variable
	\begin{align*}
		T=\frac{\lneg X - \mu}{\hat\sigma_{\lneg X}}
	\end{align*}
	is distributed as a $t$-distribution with $n-1$ degrees of freedom.
\end{theorem}


\section{Hypothesis Testing}


\begin{definition}
	The claim we initially assume to be true, formalised as a satistical
	model, is called the \emph{null hypothesis} and is denoted $H_0$.
\end{definition}

\begin{definition}
	The procedure to carry out a hypothesis test, which we call the
	\emph{test procedure} consists of:
	\begin{enumerate}
		\item Deciding on a \emph{test statistic}, which is a function
			  of the sample data.
		\item Determining what the distribution of the test statistic would
			  be if it arose from the null hypothesis statistical model.k
		\item Either \begin{enumerate}
			\item Deciding on a \emph{rejection region}, i.e. regions of
				  the distribution of the test statistic under $H_0$ in
				  which we should ject $H_0$. Typically, there are extremities
				  of the distribution. If our test statistic falls in to the
				  rejection region, reject $H_0$; otherwise, don't reject it.
			\item Returning a \emph{$p$-value}, which tells us how compatible
				  the test statistic is with the distribution predicted by chance
				  from $H_0$.
		\end{enumerate}
	\end{enumerate}
\end{definition}

\begin{definition}
	The $p$-value is the probability, calculated assuming the null
	hypothesis $H_0$ is true, of obtaining a value of the test statistic
	at least as contradictory to $H_0$ as the value calculated from
	the available sample.
\end{definition}

\begin{definition}
	Let there be $k$ groups of outcomes. Let $n_1,...,n_k$ be the observed
	number of occurences in each group and let $p_1,...,p_k$ be the
	expected proportion of the population in each group. Then the
	\emph{chi-squared} statistic is defined as
	\begin{align*}
		\chi^2 = \sum_{i=1}^k \frac{(n_i-np_i)^2}{np_i}
	\end{align*}
	where $n$ is the total number of observations, i.e. $n=n_1+\cdots+n_k$.
\end{definition}

\begin{theorem}
	A higher $\chi^2$ statistic indicates a poor \emph{goodness-of-fit}
	between the assumed model and the observed data. An extremely low
	$\chi^2$ value may, however, indicate that the integrity of the data
	has been compromised.
\end{theorem}


\section{Logistic Regression}


\subsection{Odds and odds ratios}

\begin{definition}
	The \emph{odds} of an event $A$ are defined as
	\begin{align*}
		\text{Odds}(A) = \frac{\P(A)}{1-\P(A)}.
	\end{align*}
\end{definition}

\begin{definition}
	The \emph{odds ratio} of an event $A$ with respect to another event
	$B$ is given by 
	\begin{align*}
		\text{OR}(x) = \frac{\text{Odds}(A|B)}{\text{Odds}\left(A|\lneg B\right)}.
	\end{align*}
\end{definition}

\subsection{Logistic regression model}

\begin{definition}
	The \emph{logistic function} $\sigma:\R\to\R$ is defined as
	\begin{align*}
		\sigma(x) = \frac{1}{1+e^{-x}}.	
	\end{align*}
\end{definition}

\begin{definition}
	A variable $x$ that can take the two values $1$ and $-1$ is called a
	\emph{dichotomous variable}.
\end{definition}

\begin{theorem}
	Let $Y$ be a dichotomous variable dependent on $x$. Then the probability
	$\P(Y=1|x)$ may be approximated as
	\begin{align*}
		\P(Y=1|x)=\sigma(\beta_0+\beta_1 x) = \frac{1}{1+e^{-\beta_0-\beta_1 x}}.	
	\end{align*}
\end{theorem}

\begin{definition}
	The \emph{logit} function is defined as
	\begin{align*}
		\logit(p) = \ln\frac{p}{1-p}.
	\end{align*}
\end{definition}

\begin{definition}
	The \emph{log odds} of an event $A$ are defined as
	\begin{align*}
		\text{Log Odds}(A)=\logit(\P(A)).
	\end{align*}
\end{definition}

\begin{corollary}
	The logistic prediction model with dependent variable $Y$ and
	independent variable $x$ and parameters $\beta_0,\beta_1\in\R$
	may be expressed as 
	\begin{align*}
		\logit(\P(Y=1|x)) = \beta_0 + \beta_1 x.
	\end{align*}
\end{corollary}

\subsection{Multiple logistic regression}

\begin{definition}
	The logistic regression model for the $n$ independent variables $x^{(1)},
	..., x^{(n)}$ and dependent variable $Y$ with $n$ parameters
	$\beta_0,\beta_1, ..., \beta_n$ is given by
	\begin{align*}
		\P(Y=1|x^{(1)},...,x^{(n)})=\sigma(\beta_0+\beta_1 x^{(1)}+\cdots + \beta_n x^{(n)}).
	\end{align*}
\end{definition}

\paragraph{Comparison between logistic regression and $k$-NN}
\begin{enumerate}
	\item \emph{decision boundary} is a straight line
	\item less \emph{flexibility} but less \emph{over-fitting}
	\item more \emph{transparent}
	\item \emph{no standardisation} required
\end{enumerate}

\subsection{Maximum likelihood estimation of logistic regression coefficients}

\begin{definition}
	The \emph{principle of maximum likelihood} states that the model
	coefficients are to be adjusted so as to maximise the likelihood
	that the observed data arises from the model. The resulting coefficients
	are called \emph{maximum likelihood estimators}.
\end{definition}

\begin{theorem}
	Let $X$ be an independent variable and let $Y$ be dependent on $X$.
	Let $x_1,...,x_n$ and $y_1,...,y_n$ be observed values of $X$ and $Y$.
	Then the best estimates of $\beta_0,\beta_1$ in the logistic regression
	model are those that maximise
	\begin{align*}
		\sum_{i=1}^n\ln\P(Y=y_i|X=x_i) = \sum_{i=1}^n -\ln(1+\exp(-y_i(\beta_0+\beta_1x_i))).
	\end{align*}
\end{theorem}


\section{Comparing two samples}

\subsection{A/B testing}

\begin{definition}
	\emph{A/B testing} is a method for assessing how changes to design of a system
	affect user behaviour. The statistical questions in A/B testing are
	\begin{enumerate}
		\item Is A \emph{significantly} better than B?
		\item How much better is A than B?
	\end{enumerate}
\end{definition}

\paragraph{Bootstrap for A/B learning}

Let $p_A,p_B\in\R$ be the success-rate for $A$ and $B$ respectively. Then the
difference we are trying to estimate is
\begin{align*}
	d = p_A - p_B.
\end{align*}
Then the natural estimators are
\begin{align*}
	\hat p_A = \frac{n_A}{n}\hs \hat p_B = \frac{n_B}{n}
\end{align*}
where $n_A,n_B\in\N$ are the actual numbers of successes in either case.
The bootstrap procedure is
\begin{enumerate}
	\item For $j$ in $1,...,B$ \begin{enumerate}
		\item Sample $n^*_A$ from binomial distribution with parameters $n$ and $\hat p_A$
		\item Sample $n^*_B$ from binomial distribution with parameters $n$ and $\hat p_B$
		\item Compute and store difference in proportions \begin{align*}
			d^*_j = n^*_A/n - n^*_B/n
		\end{align*}
	\end{enumerate}
	\item Plot the bootstrap distribution of $d^*$ and compute the desired quantities
\end{enumerate}

\subsection{Large sample theory}

\begin{theorem}
	Given a large sample of size $n$, the estimators for A/B testing are
	\begin{align*}
		\hat p_A &= \frac{n_A}{n}\\
		\hat p_B &=\frac{n_B}{n}\\
		\hat d   &= \hat p_A - \hat p_B\\
		\hat\sigma_{\hat p_A} &= \sqrt{\frac{np_A(1-p_A)}{n}}\\
		\hat\sigma_{\hat p_B} &= \sqrt{\frac{np_B(1-p_B)}{n}}\\
		\hat\sigma_{\hat p_A} &= \sqrt{\frac{p_A(1-p_A)}{n}}\\
		\hat\sigma_{\hat p_B} &= \sqrt{\frac{np_B(1-p_B)}{n}}\\
		\hat\sigma_{\hat d}   &= \sqrt{\hat\sigma^2_{\hat p_A} + \hat\sigma^2_{\hat p_B}}
	\end{align*}
\end{theorem}


\section{Software engineering}


\paragraph{Requirements for reproducible data analysis}

\begin{itemize}
	\item data
	\item code 
	\item documentation
\end{itemize}

\subsection{Facilitators of reproducible research}

\subsubsection{Data}
\begin{itemize}
	\item Journal policies
	\item Data repositories \begin{itemize}
		\item institutional
		\item subject-specific
		\item general
		\item governmental
	\end{itemize}
\end{itemize}


\subsubsection{Code}

\begin{itemize}
	\item VCS
	\item unit testing
	\item conda environments
	\item virtual environments
\end{itemize}

\subsection{Notebooks}

\paragraph{Advantages}

\begin{itemize}
	\item Good for one-off analysis
	\item helps reproducibility by recording steps
	\item many packages have Python interfaces
	\item can be used on a remote server
\end{itemize}

\paragraph{Disadvantages}

\begin{itemize}
	\item using same procedure for new dataset (automation not interactivity)
	\item inconsistent state
	\item no object-oriented code
	\item version 
\end{itemize}

\subsection{Cleaning data}

\begin{itemize}
	\item save the raw data with details of how to obtain it
	\item back up the raw data
	\item save and share clean version of the data \begin{itemize}
		\item open data format, e.g. CSV, JSON, YAML, XML
		\item meaningful variable names
		\item metadata about meaning of columns
	\end{itemize}
	\item make sure dataset is tidy \begin{itemize}
		\item one observation per row
		\item one variable per column
		\item unit not stored with numbers
		\item ideally unique ID for each observation
	\end{itemize}
	\item if generating data, share in a repository
\end{itemize}


\section{Linear regression and inference}


\begin{theorem}
	The estimated standard error in the estimator for $\hat\beta_1$ is
	\begin{align*}
		\hat\sigma_{\hat\beta_1}=s_{\hat\beta_1}=\frac{s}{\sqrt{\sum_{i=1}^n (x_i-\lneg{x})^2}}
	\end{align*}
	where $s$ is the estimate for $\sigma$, the standard deviation of
	residuals
	\begin{align*}
		\hat\sigma^2 = s^2 = \frac{\text{SSE}}{n-2}.
	\end{align*}
\end{theorem}

\begin{theorem}
	Consider the quantity
	\begin{align*}
		T=\frac{\hat\beta_1-\beta_1}{S_{\hat\beta_1}}
	\end{align*}
	where $\beta_1$ is the true but unknown value. Then $T$ 
	has a $t$-distribution with $n-2$ degrees of freedom.
	The $100(1-\alpha)\%$ confidence interval of $\beta_1$ is given by
	\begin{align*}
		\hat\beta_1 - s_{\hat\beta_1}t_{\alpha/2,n-2} <\beta_1
		<\hat\beta_1+s_{\hat\beta_1}t_{\alpha/2,n-2}.
	\end{align*}
\end{theorem}


\end{document}
