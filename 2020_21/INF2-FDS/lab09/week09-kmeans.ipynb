{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inf2 - Foundations of Data Science\n",
    "## Week 09: K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning outcomes:** \n",
    "In this lab you will implement the K-Means algorithm from scratch.\n",
    "\n",
    "By the end of the lab you should be able to:\n",
    "- implement and explain the different steps involved in K-Means,\n",
    "- explain what the benefits of clustering algorithms are,\n",
    "- explain what partitional clustering algorithms are,\n",
    "- and be able to use sklearn's K-Means algorithm.\n",
    "\n",
    "**Research question:**\n",
    "\n",
    "In this lab we will use K-means on the same breast cancer patients data to see how many types of cancer can be distinguished.\n",
    "\n",
    "**Data set information:** \n",
    "\n",
    "The data set is adapted from [UCI](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)). It contains patient information taken from patients with breast cancer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "#Importing sklearn functions\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering refers to a group of unsupervised learning algorithms, one of which is K-means. Each cluster is a group of data points in which points should be more similar to each other than they are to points in other clusters. Clustering is used to interpret and compress data. Interpretation can help to deepen our knowledge of the dataset. For example in medicine, we might be interested in particular clusters of symptoms of a disease. For example, researchers at King's College have identified six clusters of patterns of [Coronavirus symptoms over time](https://www.medrxiv.org/content/10.1101/2020.06.12.20129056v1.full.pdf). The cluster labels can then be used as independent variables with hospitalisation as dependent variable to build a model predicting the likelihood of hospitalisation given a cluster membership.\n",
    "\n",
    "K-Means belongs to the group of *partitional clustering* algorithms, in which we partition the data into $K$ non-overlapping clusters; each data point can only belong to exactly one cluster. If you are interested in other clustering algorithms, such as *hierarchical* or *density based* clustering, we invite you to read the following [paper](https://link.springer.com/content/pdf/10.1007/s40745-015-0040-1.pdf), or take IAML in your honours years.\n",
    "\n",
    "Partitional clustering algorithms are non-deterministic, which means that each run can lead to different clusters even on the same data set. The main benefits of partitional clustering algorithms are their simplicity and low computational complexity. However, they are also only well suited for spherical clusters and do not cope well with complex shapes. \n",
    "\n",
    "The following pseudo code should help you remember from the lecture how the algorithm works:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose k centroids randomly\n",
    "# While(centroids are not the same as in the previous iteration) do:\n",
    "    # Assign each data point to its closest centroid\n",
    "    # Compute new centroid based on the mean of all the points in the cluster\n",
    "# end while"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.A Implementing K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to initialize the centroids. The easiest way would be to just take the first `K` data points. However, we also know that the result of K-Means depends on the initial centroids, and thus a random assignment is beneficial to allow for more restarts.\n",
    "\n",
    "**Exercise 01:** \n",
    "- Create a function `initialize_centroids()`. It should take as parameters `data`, a numpy 2-dimensional array in which each row is an instance ($\\mathbf x_i$ in the lecture notes) and `n_clusters` the number of clusters we are looking for ($K$ in the lecture notes). (Remark: we use `n_clusters` instead of `k_clusters`, as this is the notation used in sklearn and it won't confuse you once you use the sklearn functions.)\n",
    "- Create an array `random_data_points` with `n_clusters` random integers in the range from 0 to the length of the data set. \n",
    "\n",
    "Hint: You can either create a loop which gets a [random number](https://pynative.com/python-random-randrange/) between 0 and the length of the data set, and appends the value to the `random_data_points` array (remember that each value appended to the array needs to be distinct), or you can use [numpy's](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.permutation.html) `random.permutation` function to create an array of same length as the data set with randomly permutated integers between 0 and length of the data set, and take the first `n_clusters` values of that array and assign it to `random_data_points`. \n",
    "\n",
    "- Finally, create a new numpy array by filtering from the data sets the rows corresponding to the randomly chosen numbers. and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "def initialize_centroids(data, n_clusters):\n",
    "    return np.random.permutation(data)[:n_clusters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step consists of assigning each data point to a cluster.\n",
    "\n",
    "**Exercise 02:**\n",
    "- Create a function `assign_clusters()`. It should take as parameters `data` and `centroids`.\n",
    "- Use `pairwise_distance(data, centroids, metric='euclidean')` from the sklearn library (which we have imported above) to compute the distance of each data point to each of the centroids. Look up the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html) to understand how the function works, and what the return value is. Store the returned value in a new variable `euclidean_distance`.\n",
    "- Find the centroid that is closest to each data point, and store the array with the numbers representing the centroids for each data point in an array `assigned_clusters`. Hint: numpy's `argmin()` might help to find the centroid with the minimal distance. \n",
    "- Return `assigned_clusters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "def assign_clusters(data, centroids):\n",
    "    euclidean_distance = pairwise_distances(data, centroids, metric='euclidean')\n",
    "    assigned_clusters = np.zeros(len(data))\n",
    "    for i, x in enumerate(euclidean_distance):\n",
    "        assigned_clusters[i] = np.argmin(x)\n",
    "    return assigned_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step to compute the optimal centroids is to update the centroids, based on their assignment of the previous iteration.\n",
    "\n",
    "**Exercise 03:**\n",
    "- Create a function `update_centroids()`. It should take as parameters `data`, `n_clusters` and `assigned_clusters`.\n",
    "- For each cluster, compute the mean for each feature of all the data points in the cluster. You can use a loop or a list comprehension, and remember the numpy mean() function - but make sure you get the `axis` argument right.\n",
    "- Create a 2-dimensional array `centroids` such that each row in the matrix contains the list of means computed for each cluster.\n",
    "- Return the `centroids` as a 2-dimensional array, with each row containing one centroid.\n",
    "\n",
    "Hint: The type of the final returned value should be a ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "def update_centroids(data, n_clusters, assigned_clusters):\n",
    "    new_centroids = np.zeros((n_clusters, data.shape[1]))\n",
    "    for i in range(n_clusters):\n",
    "        new_centroids[i] = np.mean([data[j] for j, c in enumerate(assigned_clusters) if j == i], axis=0)\n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the auxiliary functions that we need to finish to write our K-means algorithm. We are going to structure the code in a similar way to sklearn.\n",
    "\n",
    "**Remark:** For every model sklearn implements there is a class with  `fit()` and `predict()` methods. The `fit()` method trains the model and the `predict()` method allows us to determine the classification of a seen or unseen data point. The term \"predict\" is perhaps a bit misleading in the case of K-means, where `.predict()` means \"determine the cluster of a data point\".\n",
    "\n",
    "**Exercise 04:**\n",
    "We have prepared a skeleton for a class called `K_Means`. We have also already prepared the constructor. Your job is now to add two methods: `fit()` and `predict()`.\n",
    "- For the `fit()` method, look at the pseudo code above, and use the three functions you have coded previously to fit the model. Store the final centroids to `self.centroids`.\n",
    "- The `predict()` method should take only one observation as input and compute to which centroid the distance is minimal, and then return the value of the centroid. (Careful: It will probably return an array with just one entry, but it should just return an integer.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    def __init__(self, n_clusters=2):\n",
    "        self.n_clusters=n_clusters\n",
    "        self.centroids=None\n",
    "    \n",
    "    def fit(self, data):\n",
    "        centroids = None\n",
    "        new_centroids = initialize_centroids(data, self.n_clusters)\n",
    "        while (centroids != new_centroids).all():\n",
    "            centroids = new_centroids\n",
    "            assigned_clusters = assign_clusters(data, centroids)\n",
    "            new_centroids = update_centroids(data, self.n_clusters, assigned_clusters)\n",
    "        self.centroids = centroids\n",
    "        \n",
    "    def predict(self, observation):\n",
    "        return assign_clusters(np.array([observation]), self.centroids)[0]\n",
    "# Your code        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** Before we apply the K-means algorithm, it is a good idea to standardize your data. Try to remember with your lab partner why standardization is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.B Applying K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given a data set of breast cancer patients. Our aim is to see if we can cluster the breast cancer data into two categories.\n",
    "\n",
    "**Exercise 05:** \n",
    "- Load the `breast_cancer.csv` data set from `datasets`. We have preprocessed the data set for you. All unnecessary columns and rows with NaN values have been removed.\n",
    "- We need to standardize the `breast_cancer` data. We can either\n",
    "  - use the standardize() from the last lab or \n",
    "  - use the sklearn `StandardScaler()` class. Here is the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "- Display your standardized data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302        17.99         10.38          122.80     1001.0   \n",
       "1    842517        20.57         17.77          132.90     1326.0   \n",
       "2  84300903        19.69         21.25          130.00     1203.0   \n",
       "3  84348301        11.42         20.38           77.58      386.1   \n",
       "4  84358402        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code\n",
    "breast_cancer = pd.read_csv('datasets/breast_cancer.csv')\n",
    "scaler = StandardScaler()\n",
    "std_data = scaler.fit_transform(breast_cancer)\n",
    "std_data.shape\n",
    "breast_cancer.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now run our K-means algorithm on our data set.\n",
    "\n",
    "**Exercise 06:**\n",
    "- Instantiate a `K_Means` object with `n_clusters=2` parameters.\n",
    "- Fit the model with your standardized data set.\n",
    "- Print the centroids.\n",
    "- Use [sklearn's native K-Means class](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) to compute the centroids, and print them out. Do you get similar results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.36405166e-01  1.09706398e+00 -2.07333501e+00  1.26993369e+00\n",
      "   9.84374905e-01  1.56846633e+00  3.28351467e+00  2.65287398e+00\n",
      "   2.53247522e+00  2.21751501e+00  2.25574689e+00  2.48973393e+00\n",
      "  -5.65265059e-01  2.83303087e+00  2.48757756e+00 -2.14001647e-01\n",
      "   1.31686157e+00  7.24026158e-01  6.60819941e-01  1.14875667e+00\n",
      "   9.07083081e-01  1.88668963e+00 -1.35929347e+00  2.30360062e+00\n",
      "   2.00123749e+00  1.30768627e+00  2.61666502e+00  2.10952635e+00\n",
      "   2.29607613e+00  2.75062224e+00  1.93701461e+00]\n",
      " [-2.36403445e-01  1.82982061e+00 -3.53632408e-01  1.68595471e+00\n",
      "   1.90870825e+00 -8.26962447e-01 -4.87071673e-01 -2.38458552e-02\n",
      "   5.48144156e-01  1.39236330e-03 -8.68652457e-01  4.99254601e-01\n",
      "  -8.76243603e-01  2.63326966e-01  7.42401948e-01 -6.05350847e-01\n",
      "  -6.92926270e-01 -4.40780058e-01  2.60162067e-01 -8.05450380e-01\n",
      "  -9.94437403e-02  1.80592744e+00 -3.69203222e-01  1.53512599e+00\n",
      "   1.89048899e+00 -3.75611957e-01 -4.30444219e-01 -1.46748968e-01\n",
      "   1.08708430e+00 -2.43889668e-01  2.81189987e-01]]\n",
      "[[-0.03754203 -0.48442497 -0.23948977 -0.50066826 -0.47922799 -0.30302374\n",
      "  -0.50766196 -0.56671617 -0.57922637 -0.30396101 -0.12545115 -0.4270387\n",
      "  -0.02125791 -0.42787555 -0.40142988 -0.00848542 -0.34569618 -0.31677152\n",
      "  -0.38607654 -0.06982168 -0.20642387 -0.51730476 -0.25182285 -0.53018015\n",
      "  -0.49893721 -0.3025456  -0.47291642 -0.51940106 -0.57008917 -0.29713594\n",
      "  -0.30959659]\n",
      " [ 0.07548132  0.97397614  0.48151381  1.0066346   0.96352718  0.60925407\n",
      "   1.020696    1.13942935  1.16458212  0.61113855  0.25222982  0.85859633\n",
      "   0.04274078  0.86027888  0.8071077   0.01706063  0.69505052  0.63689512\n",
      "   0.77623856  0.14038222  0.41503212  1.04008365  0.50631048  1.06597067\n",
      "   1.00315418  0.60829274  0.95083725  1.04429844  1.14621103  0.59741617\n",
      "   0.62246932]]\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "k_means = K_Means(n_clusters=2)\n",
    "k_means.fit(std_data)\n",
    "print(k_means.centroids)\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(std_data)\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** If you run the code several times, you might get a slightly different result every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 07:**\n",
    "\n",
    "In some cases, if the data set is very large the optimization can take a very long time. Add an object variable to your object called `max_iter` in the object constructor with a default value 100. Add an extra iteration variable to your loop and a condition to the loop that breaks the loop once the iterator is greater than `max_iter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 08:**\n",
    "\n",
    "Finally, we would like to plot the centroids. However, our data is high-dimensional. By now you should think \"Too many dimensions? -> PCA\".\n",
    "\n",
    "- Apply PCA to your standardized dataset - we suggest you use 3 components, but you may wish to look at how much variance is explained by each component using `pca.explained_variance_ratio_`\n",
    "- Apply K-means to the PCA scores, using `max_iter = 5`. (Run it several times to see whether the centroids remain the same.)\n",
    "- Plot the scatter plot of the first two dimensions, colouring the two clusters differently.\n",
    "- Plot the two centroids with different markers.\n",
    "- Repeat the exercise with `max_iter=100`. (Run it several times to see, whether this time the centroids have converged.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code (for max_iter=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are two reasonably well-separated clusters. Let's compare how well they match the benign and malignant clusters from the dataset from our previous lab.\n",
    "\n",
    "**Exercise 09:**\n",
    "\n",
    "- Load the `breast_cancer_diagnosis.csv` dataset, which in addition to the previous dimensions, contains the diagnosis `M` (malignant) or `B` (benign).\n",
    "- Plot the scatter plot of the first two dimensions of the pca scores from the last exercise, but this time colouring the benign and malignant classes differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10:**\n",
    "- Count the numbers of benign and malignant patients in each cluster.\n",
    "- Which cluster best corresponds to each diagnosis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "You have learned a lot in the last few labs:\n",
    "\n",
    "- Cleaning your data.\n",
    "- Plotting your data.\n",
    "- Applying PCA and K-Means.\n",
    "\n",
    "And you have used all those skills in this lab. However, there are a couple of things you should think about. Discuss the following points with your lab partner.\n",
    "\n",
    "- How could you prevent your model from overfitting to the data?\n",
    "- We have already discussed `max_iter` as one option to stop the optimization if it takes too long. What is a different criterion based on which we could stop the optimization?\n",
    "\n",
    "*Hint:* Look at the sklearn documentation of K-Means, the parameters might give you some ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need your help:** This is a new course. In order for us to improve the labs for the next iterations, and to make sure that the next labs are better, we need your feedback. Please fill out the following [form](https://forms.office.com/Pages/ResponsePage.aspx?id=sAafLmkWiUWHiRCgaTTcYZmGMCx4KxlMjSTITqjdcXpUMTNCSlU4SzhaTVAyMjJGVlRWSUtaM1ZLQi4u)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
