\documentclass{article}
\usepackage{notes-preamble}
\mkfpmthms
\usepackage{pseudo}

\title{INF2D: Reasoning and Agents (SEM4)}
\author{Franz Miltz}
\begin{document}
\maketitle
\tableofcontents
\pagebreak

\section{Intelligent agents and their environments}

\begin{definition}
    An \emph{agent} is an entity that perceives and
    acts based on a sequence of observations in a system.
\end{definition}

\begin{definition}
    A \emph{rational agent} is an agent that acts to achieve
    the best possible outcome or the best possible expected
    outcome, if uncertainty is involved.
\end{definition}

\begin{definition}
    The computing device an agent runs on combined with all sensors and actuators
    is called the agents \emph{architecture}.
\end{definition}

\subsection{Types of intelligent agents}

\begin{definition}
    \emph{Simple reflex agents} are agents that only react to the immediate percepts
    and ignore the entirety of their percept history.
\end{definition}

\begin{definition}
    \emph{Model-based reflex agents} are agents whose actions may depend on the
    percept history as well as unperceived aspects of the world. They need to
    maintain an \emph{internal world model}.
\end{definition}

\begin{definition}
    \emph{Goal-based agents} are agents that have variable goals depending on the
    state of their environment.
\end{definition}

\begin{definition}
    \emph{Utitlity-based agents} are agents that can prioritise between multiple, 
    potentially conflicting goals at the same time.
\end{definition}

\subsection{Types of environments}

\begin{definition}
    If the agents sensors descirbe an environment fully, it is called
    \emph{fully observable}. Otherwise, it is \emph{partially observable}.
\end{definition}

\begin{definition}
    If the next state of an environment is fully determined by the current state
    and the agents actions, it is called \emph{deterministic}. Otherwise, it is
    \emph{stochastic}.
\end{definition}

\begin{definition}
    If the next action within an environment does not depend on the previous actions
    it is called \emph{episodic}. Otherwise, it is \emph{sequential}.
\end{definition}

\begin{definition}
    If the an environment does not change while the agent determines his next action
    it is called \emph{static}. Otherwise, it is \emph{dynamic}.
\end{definition}

\begin{definition}
    If the percepts, actions and episodes within an environment are discrete, it is called
    \emph{discrete}. Otherwise, it is \emph{continuous}.
\end{definition}


\section{Problem solving and search}


\subsection{Types of problems}

\begin{definition}
    If the environment is deterministic and fully observable
    the problem is called a \emph{single-state problem}.
    The agent knows exactly which state it will be in and the
    solution is a \emph{sequence}.
\end{definition}

\begin{definition}
    If the environment is non-observable the problem is called
    \emph{sensorless}. The agent may have no information about
    the state of the environment and the solution is a
    \emph{sequence}.
\end{definition}

\begin{definition}
    If the environment is non-deterministic and/or partially 
    observable the problem is called a \emph{contingency problem}.
\end{definition}

\begin{definition}
    If the state space is unknown to the agent, the problem is
    called an \emph{exploration problem}.
\end{definition}

\subsection{Problem formulation}

\begin{definition}[Problem formulation]
    A single-state problem in state space $S$
    and action space $A$ is defined by
    \begin{enumerate}
        \item \emph{initial state}
        \item \emph{successor function}, $f:S\to A\times S$
        \item \emph{goal test}, explicit or implicit
        \item additive \emph{path cost}, $c:S\times A\times S\to\R_{\geq 0}$
    \end{enumerate}
\end{definition}

\subsection{Selecting a state space}

Complexity of real world needs to be abstracted away.
\begin{itemize}
    \item \emph{(abstract) state}: set of real states
    \item \emph{(abstract) action}: complex combination of real actions
    \item \emph{(abstract) solution}: set of real paths, solutions in the real world
\end{itemize}

\subsection{Tree search algorithms}

\emph{Idea}: offline, simulated exploration of state space by generating successors of already
explored states.

\begin{pseudo}
\textbf{function} TREE-SEARCH(problem) \textbf{returns} a solution or failure   \\+
    initialise the frontier using the initial state of the problem              \\
    \textbf{loop do}                                                            \\+
        \textbf{if} the frontier is empy \textbf{then}                          \\+
            \textbf{return} failure                                             \\-
        choose a leaf node and remove it from the frontier                      \\
        \textbf{if} the node contains a goal state \textbf{then}                \\+
            \textbf{return} the corresponding solution                          \\-
        expand the chosen node, adding the resulting nodes to the frontier
\end{pseudo}


\section{Search strategies}


\begin{definition}
    A \emph{search strategy} defines the order of expansion in a tree search algorithm.
\end{definition}

\begin{definition}
    Search strategies are \emph{evaluated} along the following
    dimensions
    \begin{itemize}
        \item \emph{completeness}
        \item \emph{time complexity}
        \item \emph{space complexity}
        \item \emph{optimality}
    \end{itemize}
\end{definition}

\begin{pseudo}
\textbf{function} GRAPH-SEARCH(problem) \textbf{returns} a solution or failure  \\+
    initialise the frontier using the initial state of the problem              \\
    \textbf{loop do}                                                            \\+
        \textbf{if} the frontier is empy \textbf{then}                          \\+
            \textbf{return} failure                                             \\-
        choose a leaf node and remove it from the frontier                      \\
        \textbf{if} the node contains a goal state \textbf{then}                \\+
            \textbf{return} the corresponding solution                          \\-
        \emph{add the node to the explored set}                                 \\
        expand the chosen node, adding the resulting nodes to the frontier      \\+
            \emph{\textbf{only if} not in the frontier or explored set}
\end{pseudo}

\subsection{Breadth-first search}

\begin{definition}
    \emph{Breadth-first search} is a search strategy where
    the frontier is a FIFO queue.
    \begin{pseudo}
    \textbf{function} BREADTH-FIRST-SEARCH(problem) \textbf{returns} a solution or failure  \\+
        \emph{node} $\leftarrow$ a node with STATE=\emph{problem}.INITIAL-STATE, PATH-COST=0\\
        \textbf{if} \emph{problem}.GOAL-TEST(\emph{node}.STATE) \textbf{then}               \\+
            \textbf{return} SOLUTION(\emph{node})                                           \\-
        \emph{frontier} $\leftarrow$ FIFO queue only containing \emph{node}                 \\
        \emph{explored} $\leftarrow \emptyset$                                              \\
        \textbf{loop do}                                                                    \\+
            \textbf{if} EMPTY?(\emph{frontier}) \textbf{then}                               \\+
                \textbf{return} failure                                                     \\-
            \emph{node} $\leftarrow$ POP(\emph{frontier})                                   \\
            add \emph{node}.STATE to \emph{explored}                                        \\
            \textbf{for each} \emph{action} $\in$ \emph{problem}.ACTIONS(\emph{node}.STATE) \textbf{do}             \\+
                \emph{child} $\leftarrow$ CHILD-NODE(\emph{problem}, \emph{node}, \emph{action})                    \\
                \textbf{if} \emph{child}.STATE $\not\in$ \emph{explored} $\cup$ \emph{frontier} \textbf{then}       \\+
                \textbf{if} \emph{problem}.GOAL-TEST(\emph{child}.STATE) \textbf{then return} SOLUTION(\emph{child})\\
                \emph{frontier} $\leftarrow$ INSERT(\emph{child}, \emph{frontier})
    \end{pseudo}
\end{definition}

\begin{theorem}
    The breadth-first search strategy on a problem with branching factor $b$,
    depth $d$ and maximum depth $m$ may be evaluated as follows:
    \begin{itemize}
        \item complete: yes, if $b$ is finite
        \item time complexity: $O(b^d)$
        \item space complexity: $O(b^d)$
        \item optimal: yes, if each step has equal cost
    \end{itemize}
\end{theorem}

\subsection{Depth-first search}

\begin{definition}
    \emph{Depth-first search} is a search strategy where the frontier is
    a LIFO queue.
\end{definition}

\begin{theorem}
    The depth-first search strategy on a problem with branching factor $b$,
    depth $d$ and maximum depth $m$ may be evaulated as follows:
    \begin{itemize}
        \item complete: no, fails for loops and infinite-depth spaces
        \item time complexity: $O(b^m)$ 
        \item space complexity: $O(bm)$
        \item optimal: no
    \end{itemize}
\end{theorem}

\subsection{Depth-limited search}

\begin{definition}
    \emph{Depth-limited search} is a search strategy where the frontier is
    a LIFO queue and nodes at a given depth $l$ have no successors.
\end{definition}

\begin{theorem}
    The depth-limited search strategy on a problem with branching factor $b$,
    depth $d$, maximum depth $m$ and depth limit $l$ may be evaluated as follows:
    \begin{itemize}
        \item complete: yes, if $l\geq d$
        \item time complexity: $O(b^l)$
        \item space complexity: $O(bl)$
        \item optimal: no
    \end{itemize}
\end{theorem}

\subsection{Iterative deepening search}

\begin{definition}
    \emph{Iterative deepening search} is a search strategy where
    depth-limited search is performed with increasing depth limit until
    a solution is found.
\end{definition}

\begin{theorem}
    The iterative deepening search strategy on a problem with branching factor
    $b$, depth $d$ and maximum depth $m$ may be evaulated as follows:
    \begin{itemize}
        \item complete: yes
        \item time complexity: $O(b^d)$
        \item space complexity: $O(bd)$
        \item optimal: yes, if each step has equal cost
    \end{itemize}
\end{theorem}
\end{document}