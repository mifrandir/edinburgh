\documentclass{article}
\usepackage{homework-preamble}

\title{Randomised Algorithms: Coursework 2}
\author{Franz Miltz}
\begin{document}
\maketitle

Let $G=\rr{V,E}$ be an undirected finite graph with maximum degree $\Delta$, let $\Omega\subseteq\mathcal P\rr{V}$
be the set of independent sets on $G$, and let $\e:\P\rr{V}\to \cc{0,1}^V$ be the bijection
between subsets of $V$ and corresponding binary encodings, i.e. $\e\rr{x}\rr{v}=1$ iff $v\in x$.
We abuse notation and write $x\rr{v}=\e\rr{x}\rr{v}$.

Let $\pi:\mathcal P\rr{V}\to\bb{0,1}$ be the probability distribution defined by
\begin{align*}
  \pi\rr{x}=
  \begin{cases}
    \frac{\lambda^{\abs{x}}}{Z\rr{\lambda}} &\text{if }\forall \cc{v,w}\in E.\:x\rr{v}x\rr{w}=0 \\
    0 &\text{otherwise}
  \end{cases}
\end{align*}
where $Z\rr{\lambda}=\sum_{x\in\cc{0,1}^V} \lambda^{\abs{x}}$.

Let $\rr{X_t}_{t\geq 0}$ be the discrete time stochastic process associated with the Glauber dynamics
update. That is, for all $t\geq 0$, $X_t$ takes values in $\Omega$ and an update is
performed in two steps from a state $X_t=x$:
\begin{enumerate}
  \item An element $v\in V$ is chosen uniformly at random.
  \item A new state $y\in\Omega\rr{x,v}$ is chosen uniformly at random.
\end{enumerate}
Here $\Omega\rr{x,v}=\cc{y\in\Omega : \forall w\neq v.\: x\rr{w}=y\rr{w}}$.

\begin{claim*}[1]
  Let $\rr{Y_t}_{t\geq 0}$ be a discrete time stochastic process over $\Omega$ with the
  following transition rule from a given state $Y_t=x$ to a state $Y_{t+1}=y$:
  \begin{enumerate}
    \item An element $v\in V$ is chosen uniformly at random.
    \item For all $w\neq v$, $y\rr{w}=x\rr{w}$.
    \item If there is an $w\in N\rr{v}$ such that $x\rr{w}=1$ then $y\rr{v}=0$.
    \item Else, assign $y\rr{v}=1$ with probability $\lambda/\rr{1+\lambda}$ and $y\rr{v}=0$
      with probability $1/\rr{1+\lambda}$.
  \end{enumerate}
  There exists a $\lambda>0$ such that
  the processes $\rr{X_t}_{t\geq 0}$ and $\rr{Y_t}_{t\geq 0}$ are equivalent.
  \begin{proof}
    Let $x,y\in\Omega$ and $t\geq 0$. Let $x\ominus y= \rr{x\setminus y}\cup \rr{y\setminus x}$.
    Thus we calculate
    \begin{align*}
      \prc{X_{t+1}=y}{X_{t}=x} =
      \begin{cases}
        \sum_{v\in V} \frac{1}{\abs{V}\abs{\Omega\rr{x,v}}} &\text{if }\abs{x\ominus y}=0 \\
        \frac{1}{2\abs{V}} &\text{if } \abs{x\ominus y}=1 \\
        0 &\text{if } \abs{x\ominus y} > 1 \\
      \end{cases}
    \end{align*}
    The $\abs{x\ominus y}=0$ case follows as, for each $v\in V$, there are $\abs{\Omega\rr{x,v}}$
    possible states to transition to but only one of them leads to the desired case.
    In the $\abs{x\ominus y}=1$ the transition requires precisely one vertex $v\in V$ to be selected,
    such that $y\in\Omega\rr{x,v}$. After this has occurred, we note that there are
    $\abs{\Omega\rr{x,v}}=2$ further choices of which precisely one leads to success.
    Finally, if $\abs{x\ominus y} > 1$ then $y\not\in\Omega\rr{x,v}$ for any $v\in V$
    so the transition is impossible.

    We clearly have
    \begin{align*}
      \prc{Y_{t+1}=y}{Y_t=x, \abs{x\ominus y}>1} = \prc{X_{t+1}=y}{X_t=x, \abs{x\ominus y}>1} = 0
    \end{align*}
    as each update only affects at most one vertex. This is independent of the choice of $\lambda$.

    Further, we break the case $\abs{x\ominus y}=1$
    into $x\subset y$ and $x\supset y$. We then find
    \begin{align*}
      \prc{Y_{t+1}=y}{Y_t=x, x\subset y} = \frac{1}{\abs{V}} \frac{\lambda}{1+\lambda}
    \end{align*}
    and
    \begin{align*}
      \prc{Y_{t+1}=y}{Y_t=x, x\supset y} = \frac{1}{\abs{V}} \frac{1}{1+\lambda}.
    \end{align*}
    For equivalence of $\rr{X_t}_{t\geq 0}$ and $\rr{Y_t}_{t\geq 0}$ we now require
    \begin{align*}
      \prc{Y_{t+1}=y}{Y_t=x, x\subset y} = \prc{Y_{t+1}=y}{Y_t=x, x\supset y},
    \end{align*}
    i.e.
    \begin{align*}
      \frac{1}{\abs{V}} \frac{\lambda}{1+\lambda} = \frac{1}{\abs{V}} \frac{1}{1+\lambda}.
    \end{align*}
    Thus we choose $\lambda = 1$. Note that this leads to
    \begin{align*}
      \prc{Y_{t+1}=y}{Y_t=x, x\subset y} = \prc{Y_{t+1}=y}{Y_t=x, x\supset y}=\prc{X_{t+1}=y}{X_t=x, \abs{x\ominus y}=1}.
    \end{align*}

    It remains to show
    \begin{align}
      \label{eq:equal-case}
      \prc{X_{t+1}=y}{X_t=x, x=y}= \prc{Y_{t+1}=y}{Y_t=x, x=y}.
    \end{align}
    We obtain
    \begin{align*}
      \prc{Y_{t+1}=y}{Y_t=x, x=y}
      &= \frac{1}{\abs{V}} \rr{\sum_{v\in x} \frac{\lambda}{\rr{\lambda + 1}} + \sum_{v\in N\rr{x}} 1 + \sum_{v\in V\setminus\rr{x\cup N\rr{v}}} \frac{1}{\lambda+1}} \\
      &= \frac{1}{\abs{V}} \rr{\frac{\abs{x}\lambda}{\lambda + 1} + \abs{N\rr{x}} + \frac{\abs{V}-\abs{x}-\abs{N\rr{x}}}{\lambda + 1}} \\
      &= \frac{1}{\abs{V}} \rr{\abs{N\rr{x}} + \frac{\abs{V}-\abs{N\rr{x}}}{2}}
    \end{align*}
    where $N\rr{x}=\cc{v \in V : \exists u\in x. \: v\in N\rr{u}}$. This may be derived as follows:
    In the case where $v\in x$ the condition in (3.) fails and we require $y\rr{v}=1$ so we have
    a probability of success $\lambda/\rr{1+\lambda}$. In the case where $v\in N\rr{x}$ (note $x$
    is an independent set so $x\cap N\rr{x}=\emptyset$) the condition in the third step will
    always hold, leading to a guaranteed success. Finally, if $v\not\in x$ and $v\not\in N\rr{x}$
    then we require $y\rr{v}=0$ so the probability is $1/\rr{\lambda + 1}$.
    
    Now (\ref{eq:equal-case}) is equivalent to
    \begin{align}
      \label{eq:explicit-equal-case}
      \sum_{v\in V} \frac{1}{\abs{V}\abs{\Omega\rr{x,v}}} = \frac{1}{\abs{V}} \rr{\abs{N\rr{x}} + \frac{\abs{V}-\abs{N\rr{x}}}{2}}.
    \end{align}
    We now observe
    \begin{align*}
      \abs{\Omega\rr{x,v}} =
      \begin{cases}
        1 & \text{if } v\in N\rr{x} \\
        2 & \text{otherwise}
      \end{cases}
    \end{align*}
    I.e.
    \begin{align*}
      \sum_{v\in V} \frac{1}{\abs{\Omega\rr{x,v}}} = \sum_{v\in N\rr{x}} 1 + \sum_{v\in V\setminus N\rr{x}} \frac{1}{2} =  \abs{N\rr{x}} + \frac{\abs{V}-\abs{N\rr{x}}}{2}
    \end{align*}
    which proves (\ref{eq:explicit-equal-case}) and thus (\ref{eq:equal-case}).
  \end{proof}
\end{claim*}

\begin{claim*}[2]
  $\pi$ satisfies the detailed balance condition of the Markov chain $P$ associated
  with the stochastic process $\rr{X_t}_{t\geq 0}$.
  \begin{proof}

  \end{proof}
\end{claim*}

Let $\rr{X_t}_{t\geq 0}$ and $\rr{Y_t}_{t\geq 0}$ be coupled Markov chains that transition
based on the Glauber dynamics update where the same vertex is chosen for both chains.

Moreover, for independent sets $X,Y\subseteq V$, define their distance by
\begin{align*}
  d\rr{X,Y} = \sum_{v\in V} \abs{x\rr{v}-y\rr{v}}.
\end{align*}

\begin{claim*}[3]
\end{claim*}

\end{document}
